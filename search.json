[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Workbench Developer‚Äôs Guide",
    "section": "",
    "text": "Preface\nThe Carpentries Workbench is a open-source and portable lesson infrastructure built with the R programming language. Despite it being built in R, contributors do not need to know any R in order to use it to build reliable, stylish, and accessible lessons.\nThis book serves as development documentation for The Carpentries Workbench. It was written between June and December 2023 primarily to orient new developers and contributors to The Workbench ecosystem.\n\n\n\n\n\n\nUnder Construction üöß\n\n\n\nThe content for this site is still being written! Please check back if what you are looking for does not exist or, open an issue at https://github.com/carpentries/workbench-dev/issues/ to request it!\n\n\n\n\n\n\n\n\nPrerequisite\n\n\n\nThis book assumes familiarity with R Package Development. If you are unfamiliar, please read R Packages (2e) (Wickham and Bryan 2023).\n\n\n\n\n\n\nWickham, Hadley, and Jennifer Bryan. 2023. ‚ÄúR Packages (2e).‚Äù https://r-pkgs.org/."
  },
  {
    "objectID": "intro.html#sec-local",
    "href": "intro.html#sec-local",
    "title": "1¬† Introduction",
    "section": "1.1 Building Lessons",
    "text": "1.1 Building Lessons\nIn a broad sense, this is what happens when you run sandpaper::serve() or sandpaper::build_lesson(). The interaction between the three Workbench packages, the lesson content, and the author can be summarised like this where the author makes an edit:\n\n\n\n\n\n\nSummary Content\n\n\n\nThis content is a general picture of what happens between the packages. For a more in-depth discussion and more detailed diagrams, please visit the Flow Diagrams page.\n\n\n\n\n\n\nsequenceDiagram\n    autonumber\n    actor Author\n    participant Lesson \n    box rgb(255, 214, 216) The Workbench\n    participant {sandpaper}\n    participant {pegboard}\n    participant {varnish}\n    end\n\n    Author -&gt;&gt; {sandpaper}: sandpaper::serve()\n    activate Author\n    {sandpaper} --) Author: website preview\n    note left of {sandpaper}: monitor for changes\n    Author -&gt;&gt; Lesson: make an edit\n    deactivate Author\n    Lesson --&gt;&gt; {sandpaper}: READ changed file(s)\n    {sandpaper} --&gt;&gt; {pegboard}: validate Lesson\n    activate {pegboard}\n    note left of {sandpaper}: provision global menu elements\n    {pegboard} --) Author: report accessibility \n    deactivate {pegboard}\n    activate {sandpaper}\n    note left of {sandpaper}: WRITE markdown\n    {varnish} --&gt;&gt; {sandpaper}: load and apply website template\n    note left of {sandpaper}: WRITE website\n    {sandpaper} --) Author: website preview\n    deactivate {sandpaper}\n\n\n\n\n\nIn terms of folder structure, the workflow runs the two-step workflow to first render markdown files into site/built and then uses those files to render the HTML, CSS, and JavaScript into site/built. These workflows are detailed in The Workflows Chapter.\n\n\n\n\nflowchart TB\n    classDef default color:#383838,fill:#FFF7F1,stroke-width:1px\n    classDef external color:#383838,fill:#E6EEF8,stroke-width:1px\n    classDef normal color:#081457,fill:#E3E6FC,stroke-width:1px\n    classDef local fill:#FFC700,stroke:#333,stroke-width:1px\n    classDef remote fill:#D2BDF2, color:#201434,stroke-width:1px\n\n    SERVE(\"serve()\"):::normal\n    BLESS(\"build_lesson()\"):::normal\n\n    subgraph \"Core Workflow\"\n    BUILT[\"site/built\"]:::local\n    SITE[\"site/docs\"]:::local\n    VLESS(\"validate_lesson()\"):::normal\n    BUILDMD([\"build_markdown()\"]):::normal\n    BUILDSITE([\"build_site()\"]):::normal\n    end\n\n    %%BUILT ~~~ SITE\n\n    SERVE --&gt; BLESS\n    %% SERVE ~~~ VLESS\n    %% SERVE ~~~ BUILDMD\n    BLESS --&gt; VLESS\n    VLESS -.- BUILDMD\n    BLESS --&gt; BUILDMD\n    BUILDMD --&gt; BUILT\n    BUILT -.- BUILDSITE\n    VLESS -.- BUILDSITE\n    BLESS --&gt; BUILDSITE\n    BUILDSITE --&gt; SITE\n\n\n\n\n\n\n\n\n\n\n\nResource folder names\n\n\n\nThe names of the folders inside site/ are considered internal resources and they can change at any time. The reason why the folder for the final website output is called site/docs/ is because we use the {pkgdown} package to provision the website without needing to bundle the templates inside of {sandpaper}, but we never got around to explicitly changing the name of that folder.\n\n\nThe site/docs folder contains the full website that can be safely used offline. This is the core of the workflow and is used both locally and in a remote setting. The only difference with the remote setting is that we use a few Git tricks to provision the markdown cache without needing to store it in the default branch."
  },
  {
    "objectID": "intro.html#sec-remote",
    "href": "intro.html#sec-remote",
    "title": "1¬† Introduction",
    "section": "1.2 Building Lessons Remotely (e.g.¬†on GitHub)",
    "text": "1.2 Building Lessons Remotely (e.g.¬†on GitHub)\nIn the remote workflow, we still use the same workflow as above, except now we use ci_deploy() to link the branches and folders using worktrees, which you can think of as Git branches assigned to separate folders.\n\n\n\n\n\n\nPlatform Independence\n\n\n\nWhen we developed The Workbench, GitHub was the most widely used platform for social coding that represented the easiest way for newcomers to contribute to our lessons. We used this knowledge to build the workflows for the lessons on GitHub, but we were also aware of the valid criticisms of GitHub and the dangers of vendor lock-in.\nThus, while the lessons are deployed using GitHub workflows and we have features that handle pull requests and updates, the core deployment features remain platform-independent. The workflows are merely instructions that we provide for GitHub to set up the workbench and to run the individual functions. In theory, any platform can be configured to deploy lessons via The Workbench.\nIn fact, in a pinch when GitHub workflows are not working properly, a lesson maintainer could run sandpaper:::ci_deploy() to render and deploy a local copy of the lesson.\n\n\n\n\n\n\nflowchart TB\n    classDef default color:#383838,fill:#FFF7F1,stroke-width:1px\n    classDef external color:#383838,fill:#E6EEF8,stroke-width:1px\n    classDef normal color:#081457,fill:#E3E6FC,stroke-width:1px\n    classDef local fill:#FFC700,stroke:#333,stroke-width:1px\n    classDef remote fill:#D2BDF2,stroke:#201434,stroke-width:1px\n    classDef notouch fill:#F99697,stroke:#A4050E,stroke-width:1px\n\n\n    GH[(\"@main\")]:::remote\n    MDOUT[(\"@md-outputs\")]:::notouch\n    PAGES[(\"@gh-pages\")]:::notouch\n    DEPLOY([\"ci_deploy()\"]):::external\n    CIBUILDMD([\"ci_build_markdown()\"]):::external\n    CIBUILDSITE([\"ci_build_site()\"]):::external\n\n    subgraph GitHub Actions Runner\n    REPO[\"[repo]\"]:::local\n    BUILT[\"[repo]/site/built\"]:::local\n    SITE[\"[repo]/site/docs\"]:::local\n    VLESS(\"validate_lesson()\"):::normal\n    BUILDMD([\"build_markdown()\"]):::normal\n    BUILDSITE([\"build_site()\"]):::normal\n    end\n\n\n    GH ---&gt; REPO\n    GH ~~~ DEPLOY\n    REPO -.- VLESS\n\n\n    DEPLOY ---&gt; VLESS\n    DEPLOY ---&gt; CIBUILDMD\n    DEPLOY ---&gt; CIBUILDSITE\n    VLESS -.- BUILDMD\n    CIBUILDMD ---&gt; MDOUT\n    MDOUT &lt;-.-&gt; BUILT\n    CIBUILDMD ---&gt; BUILDMD\n    CIBUILDSITE ---&gt; PAGES\n    PAGES &lt;-.-&gt; SITE\n    CIBUILDSITE ---&gt; BUILDSITE\n    BUILT -.- BUILDSITE\n    VLESS -.- BUILDSITE\n    BUILDMD --&gt; BUILT\n    BUILDSITE --&gt; SITE"
  },
  {
    "objectID": "intro.html#development",
    "href": "intro.html#development",
    "title": "1¬† Introduction",
    "section": "1.3 Development",
    "text": "1.3 Development\nDevelopment of The Workbench is overseen by Zhian N. Kamvar. New features are added incrementally as pull requests. Pushes to the main branch are rare and discouraged. New features must have tests associated (with the exception of {varnish}).\nIf you are interested, we have documentation for the release process available."
  },
  {
    "objectID": "intro.html#documentation",
    "href": "intro.html#documentation",
    "title": "1¬† Introduction",
    "section": "1.4 Documentation",
    "text": "1.4 Documentation\nReference documentation for individual functions for each package is written alongside the function using {roxygen2}.\nThis documentation is generated by devtools::document()"
  },
  {
    "objectID": "intro.html#testing",
    "href": "intro.html#testing",
    "title": "1¬† Introduction",
    "section": "1.5 Testing",
    "text": "1.5 Testing\nTests for each package live in tests/testthat/ and follow a test-[file-name].R naming convention. These are controlled by the {testthat} package and run by devtools::test().\nYou can find more information about testing the core packages in Testing The Workbench"
  },
  {
    "objectID": "intro.html#continous-integration",
    "href": "intro.html#continous-integration",
    "title": "1¬† Introduction",
    "section": "1.6 Continous Integration",
    "text": "1.6 Continous Integration\nThe continous integration for each package tests on Ubuntu, MacOS, and Windows systems with the last five versions of R (same as the RStudio convention).\nMore information about the Continous Integration can be found in the Continuous Integration section of the testing section.\n\nComing up:\n\nTesting Pull Requests (Locally and on your fork)\nResources for R package development\nAdding functionality to {sandpaper}\nAdding functionality to {pegboard}\nAdding styling elements to {varnish}\nAdding functionality to carpentries/actions"
  },
  {
    "objectID": "setup.html#software-tools",
    "href": "setup.html#software-tools",
    "title": "2¬† System Setup",
    "section": "2.1 Software Tools",
    "text": "2.1 Software Tools\nDevelopment of Workbench components requires the same toolchain for working on lessons:\n\nR\npandoc\nGit\n\nIt is recommended to have the latest versions of R and pandoc available. You need at least git 2.28 for security purposes.\n\n\nR version\n---\n\n\nR version 4.3.1 (2023-06-16) -- \"Beagle Scouts\"\nCopyright (C) 2023 The R Foundation for Statistical Computing\nPlatform: x86_64-pc-linux-gnu (64-bit)\n\nR is free software and comes with ABSOLUTELY NO WARRANTY.\nYou are welcome to redistribute it under the terms of the\nGNU General Public License versions 2 or 3.\nFor more information about these matters see\nhttps://www.gnu.org/licenses/.\n\n\n\npandoc version\n---\n\n\npandoc 2.19.2\nCompiled with pandoc-types 1.22.2.1, texmath 0.12.5.2, skylighting 0.13,\nciteproc 0.8.0.1, ipynb 0.2, hslua 2.2.1\nScripting engine: Lua 5.4\nUser data directory: /home/runner/.local/share/pandoc\nCopyright (C) 2006-2022 John MacFarlane. Web:  https://pandoc.org\nThis is free software; see the source for copying conditions. There is no\nwarranty, not even for merchantability or fitness for a particular purpose.\n\n\n\ngit version\n---\n\n\ngit version 2.41.0"
  },
  {
    "objectID": "setup.html#r-packages",
    "href": "setup.html#r-packages",
    "title": "2¬† System Setup",
    "section": "2.2 R Packages",
    "text": "2.2 R Packages\nOnce you have these installed, make sure to install ALL of the dependencies for the workbench:\ninstall.packages(c(\"sandpaper\", \"pegboard\", \"varnish\", \"tinkr\"),\n  dependencies = TRUE,\n  repos = c(getOption(\"repos\"), \"https://carpentries.r-universe.dev\"))\n\n\n\n\n\n\nWorking on Linux?\n\n\n\nIf you are on Linux, you will run into a couple of fun aspects that you may already be familiar with, especially if you have ever tried to install bioinformatic software:\n\nhaving to also install some extra C libraries (which are akin to R packages, but for C), such as the xslt library.\nhaving to build all packages from source\n\nYou can find detailed instructions in The Sandpaper Setup Guide, but the relevant commands are below.\n\nSystem Dependencies\nHere is the gist for Ubuntu Users to get system dependencies set up. Use The Carpentries R-Universe API to get all of the system dependencies. Here‚Äôs how to do that via CURL:\ncurl https://carpentries.r-universe.dev/stats/sysdeps 2&gt; /dev/null | jq -r '.headers[0] | select(. != null)'\nThis list can be sent to apt-get install to install everything:\nsudo apt-get install -y \\\n  $(curl https://carpentries.r-universe.dev/stats/sysdeps 2&gt; /dev/null | jq -r '.headers[0] | select(. != null)') 2&gt; /dev/null \\\n  || echo \"Not on Ubuntu\"\n\n\nBinary Packages\nTo get binary packages for your system, I will admit that it‚Äôs slightly confusing because they bury the instructions for registering your system to use binaries in the admin pages and even then, it‚Äôs kinda long. The gist is that you need to do two things:\n\nset your HTTPUserAgent header to state your R version and platform\nadd the packagemanager CRAN-like repository to R‚Äôs options:\n\nHere‚Äôs a script that you can copy and paste into ~/.Rprofile which will be run every time you start R\nlocal({\n  # Set the default HTTP user agent to get pre-built binary packages\n  RV &lt;- getRversion()\n  OS &lt;- paste(RV, R.version[\"platform\"], R.version[\"arch\"], R.version[\"os\"])\n  codename &lt;- sub(\"Codename.\\t\", \"\", system2(\"lsb_release\", \"-c\", stdout = TRUE))\n  options(HTTPUserAgent = sprintf(\"R/%s R (%s)\", RV, OS))\n\n  # register the repositories for The Carpentries and CRAN\n  options(repos = c(\n    carpentries = \"https://carpentries.r-universe.dev/\",\n    CRAN = paste0(\"https://packagemanager.posit.co/all/__linux__/\", codename, \"/latest\")\n  ))\n})\nWhen you have this set up, you can then install the workbench packages:\n# Install The Workbench and dependencies\ninstall.packages(c(\"sandpaper\", \"varnish\", \"pegboard\", \"tinkr\"), dep = TRUE)\n\n\n\nThe {sandpaper} package comes with the {usethis} package embedded (though this may change in the future). In addition, you will need the {devtools} for development.\nI would also highly recommend the {pandoc} package for managing pandoc versions (NOTE: this requires you to have a personal access token set up).\ninstall.packages(\"devtools\")\ninstall.packages(\"pandoc\")\nOnce you have devtools, be sure to run devtools::dev_sitrep() and usethis::git_sitrep() to make sure you have the tools to build The Workbench:\ndevtools::dev_sitrep()\n#&gt; ‚îÄ‚îÄ R ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n#&gt; ‚Ä¢ version: 4.3.0\n#&gt; ‚Ä¢ path: '/usr/lib/R/'\n#&gt; ‚îÄ‚îÄ devtools ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n#&gt; ‚Ä¢ version: 2.4.5\n#&gt; ‚îÄ‚îÄ dev package ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n#&gt; ‚Ä¢ package: &lt;unset&gt;\n#&gt; ‚Ä¢ path: &lt;unset&gt;\n#&gt; ‚úî All checks passed\n\nusethis::git_sitrep()\n#&gt; Git config (global)\n#&gt; ‚Ä¢ Name: 'Zhian N. Kamvar'\n#&gt; ‚Ä¢ Email: 'zkamvar@gmail.com'\n#&gt; ‚Ä¢ Global (user-level) gitignore file: &lt;unset&gt;\n#&gt; ‚Ä¢ Vaccinated: FALSE\n#&gt; ‚Ñπ See `?git_vaccinate` to learn more\n#&gt; ‚Ñπ Defaulting to 'https' Git protocol\n#&gt; ‚Ä¢ Default Git protocol: 'https'\n#&gt; ‚Ä¢ Default initial branch name: 'main'\n#&gt; GitHub\n#&gt; ‚Ä¢ Default GitHub host: 'https://github.com'\n#&gt; ‚Ä¢ Personal access token for 'https://github.com': '&lt;discovered&gt;'\n#&gt; ‚Ä¢ GitHub user: 'zkamvar'\n#&gt; ‚Ä¢ Token scopes: 'gist, repo, user, workflow'\n#&gt; ‚Ä¢ Email(s): 'zkamvar@gmail.com (primary)', ...\n#&gt; Git repo for current project\n#&gt; ‚Ñπ No active usethis project\nCreated on 2023-05-30 with reprex v2.0.2"
  },
  {
    "objectID": "setup.html#development-workflow",
    "href": "setup.html#development-workflow",
    "title": "2¬† System Setup",
    "section": "2.3 Development Workflow",
    "text": "2.3 Development Workflow\nThis development workflow is known as Test Driven Development in which a test is written before things work. This way, we can confirm that a bug is fixed once it passes the tests and we have confidence that it will not fail again.\n\nopen RStudio and switch to the project for the package you are working on\ncheckout a new branch for your feature/bug\nload package via devtools::load_all() or ctrl+shift+L ( use cmd on macOS) to load the package NAMESPACE\nrun tests (either via devtools::test() or ctrl+shift+T to run the entire test suite OR to test a single file, use the ‚Äúrun tests‚Äù button in a test file or run testthat::test_local(filter = '[FILE SLUG]')\nmodify tests for new functionality/bug fix\nadd functionality/bug fix and move to 3 unless you are ready to push\nrun check with devtools::check() or ctrl+shift+E"
  },
  {
    "objectID": "testing.html#introduction",
    "href": "testing.html#introduction",
    "title": "3¬† Testing The Workbench",
    "section": "3.1 Introduction",
    "text": "3.1 Introduction\n\nThe first stage of your testing journey is to become convinced that testing has enough benefits to justify the work. For some of us, this is easy to accept. Others must learn the hard way.\n‚Äî Wickham and Bryan, Testing Basics, R Packages second edition\n\n\nIf you use software that lacks automated tests, you are the tests.\n‚Äî Jenny Bryan source tweet (2018-09-22 01:13 UTC)\n\nEvery single package that runs code in the lesson infrastructure is tested before it ever reaches any lesson. This is important because we want to give the lesson authors and maintainers as much freedom as they need to write a lesson while maintaining predictability and integrity. We also want to give our community confidence that this system works.\nWhenever a new feature or bug fix is added to The Workbench, it is imperative that a test is associated and verified before it gets sent into production.\nTests can be run locally and via continuous integration. This page introduces some of the testing strategies used in The Workbench and the caveats that come with these strategies."
  },
  {
    "objectID": "testing.html#sec-unit-tests",
    "href": "testing.html#sec-unit-tests",
    "title": "3¬† Testing The Workbench",
    "section": "3.2 Unit Testing",
    "text": "3.2 Unit Testing\nThe tests under test/testthat/ are run in alphabetical order using the {testthat} package (see https://r-pkgs.org/testing-basics.html) via devtools::test() or devtools::check().\n\n3.2.1 Conditionally Skipped Tests\nThe tests often need special conditions in order to run and sometimes those conditions are not possible. One of the most common conditions to skip is if the testing happens on CRAN. They are very hawkish about how long test suites can run and it‚Äôs often difficult to detect the state of a CRAN machine, so it‚Äôs better to skip long-running tests or those with complex environmental dependencies on CRAN (which does not yet apply to {sandpaper})."
  },
  {
    "objectID": "testing.html#sec-ci",
    "href": "testing.html#sec-ci",
    "title": "3¬† Testing The Workbench",
    "section": "3.3 Continous Integration",
    "text": "3.3 Continous Integration\nAll the unit tests are run in continuous integration for every push and pull request that occurs. They also run every week. This provisions the current releases of the R package dependencies along with development versions of critical dependencies such as {renv}.\nIn continous integration, we run on with the following conditions to make sure it works not only on GitHub, but also on local user machines:\n\ntest coverage (no package structure) with released versions on Ubuntu Linux (though reporting is stalled)\nFor each platform (Ubuntu Linux, macOS, and Windows)\n\nR CMD check, which checks the structure of the package and documentation\nall run on these versions of R: current, devel, and two previous R versions\n\n\nBecause of occasional provisioning failures on macOS and Windows, we require only that Ubuntu Linux latest version passes check for merging pull requests."
  },
  {
    "objectID": "testing.html#sec-integration",
    "href": "testing.html#sec-integration",
    "title": "3¬† Testing The Workbench",
    "section": "3.4 Lesson Integration Testing",
    "text": "3.4 Lesson Integration Testing\nUnit tests are great for testing all functionality using known and stable inputs, it is important to test using known inputs that are in a constant state of flux: live lessons. This is where The Workbench Integration Test comes in. It will run a weekly test on a defined set of lessons using the current development versions of varnish and sandpaper. These tests are useful for three purposes:\n\nongoing integrity for the workbench lessons lessons that use different features of The Workbench such as R code execution\nreal-world effects of new sandpaper and varnish versions (including those in pull requests)\ninspecting changes in HTML and markdown output\n\nThese lessons that we use are\n\nInstructor Training\n\nLesson with the most content, contributors, activity, and used features. This particular lesson is a bit of a stress test for the infrastructure.\n\nR for SocialScientists\n\nThis is one of the first R-based lessons to be transitioned and it uses the tidyverse as a dependency.\n\nWorkbench Documentation\n\nThe workbench documentation. If this doesn‚Äôt work, nothing will.\n\nRaster and Vector Geospatial Data with R\n\nThis lesson uses R packages that rely on a geospatial software stack, which can be complex. Failures here likely mean that there are problems with provisioning external C libraries.\n\nBioConductor RNAseq\n\nLesson using BioConductor R packages by people at BioConductor. If this does not work, then there likely is a provisioning problem between BioConductor and {renv}.\n\n\n\n3.4.1 Testing sandpaper and varnish pull requests\nTo test a pull request version, you can head over the the main workflow and use the button that says ‚ÄúRun Workflow‚Äù. When you want to test a varnish or sandpaper pull request, you can use the [REPO]#[PR] syntax (e.g. carpentries/sandpaper#429 to run sandpaper pull request 429) in the entry fields for varnish and sandpaper version. If you don‚Äôt have a pull request to work from, you can use the [REPO]@[REF] syntax (e.g. carpentries/sandpaper@test-this-thing to run sandpaper test-this-thing branch).\n\n\n3.4.2 Inspecting changes\nThe output for all the tests are stored in branches that are named respective for their test repositories. For example, datacarpentry/r-socialsci/markdown and datacarpentry/r-socialsci/site contain the markdown and HTML outputs for the R for Social Scientists lesson. By inspecting the diffs from the commits, you can see how the output has changed from run to run, which is useful if you are confirming that a feature will be automatically deployed."
  },
  {
    "objectID": "testing.html#sec-ad-hoc",
    "href": "testing.html#sec-ad-hoc",
    "title": "3¬† Testing The Workbench",
    "section": "3.5 Ad-hoc Testing",
    "text": "3.5 Ad-hoc Testing\nThere are times when you cannot automate your way through testing and you just have to suck it up and get your (virtual) hands dirty. You find yourself in this kind of situation if you are testing out GitHub workflows, GitHub actions, or if you are implementing a new feature and you need to see that it works reliably and safely. It‚Äôs this point in time when you use ad-hoc testing on a brand new lesson repository that you give yourself permission to mess around in and will delete when finished.\n\n3.5.1 GitHub Workflows\nA GitHub Workflow is a YAML document that lives inside the .github/workflows folder of a repository. This sets up the environment needed to build a lesson. When you debug these, ask yourself if you really want to update the GitHub Actions instead. Because these are copied to each lesson, they need to be updated in each lesson (which is accomplished through the automated pull request workflow). If you‚Äôve determined that the workflow needs to be modified, you can modify them inside your test lesson until you get the desired results. Once that is done, copy them over to sandpaper/inst/workflows and add a NEWS item that‚Äôs under the heading ## CONTINUOUS INTEGRATION describing your change.\n\n\n3.5.2 GitHub Actions\nA GitHub Action is a single step in a GitHub Workflow and can be written in nearly any language.\nThe GitHub actions that are in carpentries/actions are written in BASH, node JavaScript, and R and cobbled together with YAML. When developing a new feature, work on a branch and then, in your shiny new test lesson, replace the @main in the GitHub Workflows to your branch name. This way, you can know immediately if the fix or feature worked without having to interrupt someone‚Äôs flow.\n\n\n3.5.3 New config items or settings\nIf you implement a new config item (e.g.¬†a lang: tag), a temporary lesson is a great way to test it. To do so, you can use the sandpaper: or varnish: keys in your lesson config to specify the version of sandpaper or varnish you want to test."
  },
  {
    "objectID": "flow.html#introduction",
    "href": "flow.html#introduction",
    "title": "4¬† Flow Diagrams",
    "section": "4.1 Introduction",
    "text": "4.1 Introduction\nThis section builds on The broad workflow and details the internal process that are invoked with the sandpaper::build_lesson() function. If you look at the source for this function, it contains a total of sevens significant lines of code (many more due to documentation and comments).\nThe pre-flight steps all happen before a single source file is built. These check for pandoc, validate the lesson, and configure global elements. The last two lines are responsible for building the site and combining them with the global variables and templates.\nUsers will invoke this function in the following ways:\n\n\n\n\n\n\n\n\nvenue\nfunction\npurpose\n\n\n\n\nlocal\nsandpaper::build_lesson()\nrender content for offline use\n\n\nlocal\nsandpaper::serve()\ndynamically render and preview content\n\n\nremote\nsandpaper:::ci_deploy()\nrender content and deploy to branches\n\n\n\nAll of these methods will call sandpaper::validate_lesson() (which also sets up global metadata and menu variables) and the two-step internal functions sandpaper:::build_markdown() and sandpaper:::build_site(). Below, I break down and detail the process for each."
  },
  {
    "objectID": "flow.html#preflight-checks",
    "href": "flow.html#preflight-checks",
    "title": "4¬† Flow Diagrams",
    "section": "4.2 Preflight Checks",
    "text": "4.2 Preflight Checks\nBefore a lesson can be built, we need to confirm the following:\n\nWe have access to the tools needed to build a lesson (e.g. pandoc). This is achieved via the sandpaper::check_pandoc()\nWe are inside a lesson that can be built with The Carpentries Workbench"
  },
  {
    "objectID": "flow.html#validate-lesson",
    "href": "flow.html#validate-lesson",
    "title": "4¬† Flow Diagrams",
    "section": "4.3 validate_lesson()",
    "text": "4.3 validate_lesson()\nThe lesson validator is a bit of a misnomer. Yes, it does peform lesson validation, which it does so through the methods in the pegboard::Lesson R6 class.\nIn order to use thse methods, it first loads the lesson, via the sandpaper::this_lesson() function, which loads and caches the pegboard::Lesson object. It also caches elements that are mostly duplicated across episodes with small tweaks for each episode:\n\nmetadata in JSON-LD format\nsidebar\nextras menu for learner and instructor views"
  },
  {
    "objectID": "flow.html#build-markdown",
    "href": "flow.html#build-markdown",
    "title": "4¬† Flow Diagrams",
    "section": "4.4 build_markdown()",
    "text": "4.4 build_markdown()\n\n4.4.1 Generating Markdown\nMarkdown generation for the lesson is controlled by the internal function sandpaper:::build_markdown().\nWhen a lesson contains R Markdown files, these need to have content rendered to markdownsot hat we can further process them. This content is processed with the {knitr} R package in a separate R process. Markdown source content on the other hand is copied to the site/built folder.\nBecause R Markdown files can take some time to render, we use MD5 sums of the episode contents (stored in the site/built/md5sum.txt file) to skip any files that have not changed.\n\n\n\n\nsequenceDiagram\n    autonumber\n    participant episodes/episode.Rmd\n    box rgb(255, 214, 216) The Workbench\n    participant {sandpaper}\n    end\n    box rgb(230, 234, 240) Document Engine\n    participant {renv}\n    participant {knitr}\n    end\n    box rgb(255, 231, 168) Generated Files\n    participant site/built/md5sum.txt\n    participant site/built/episode.md\n    end\n\n    site/built/md5sum.txt --&gt;&gt; {sandpaper}: READ file cache\n    {sandpaper} --&gt;&gt; {knitr}: RUN conversion\n    episodes/episode.Rmd --&gt;&gt; {knitr}: PROCESS changed file(s)\n    {knitr} --&gt;&gt; site/built/episode.md: WRITE Markdown\n    {sandpaper} --&gt;&gt; site/built/md5sum.txt: WRITE file cache\n\n\n\n\n\n\n\n\n\n\n\nPackage Cache and Reproducibility\n\n\n\nOne package that is missing from the above diagram is {renv} and that‚Äôs partially because it has an indirect effect on the lesson: it provisions the packages needed to build the lesson.\nWhen episodes are rendered from R Markdown to Markdown, we attempt to reproduce the build environment as closely as possible by using the {renv} package. If the global package cache from {renv} is available, then the lesson profile is activated before the episode is sent to {knitr} and R will use the packages provided in that profile. This has two distinct advantages:\n\nThe user does not have to worry about overwriting packages in their own library (i.e.¬†a graduate researcher working on their dissertation does not want to have to rewrite their analyses because of a new version of {sf})\nThe package versions will be the same as the versions on the GitHub version of the site, which means that there will be no false positives of new errors popping up\n\nFor details on the package cache, see the Building Lessons With A Package Cache article.\n\n\nAt this step, the markdown has been written and the state of the cache is updated so if we re-run this function, then it will show that no changes have occured. After this step, the internal function sandpaper:::build_site() is run where the markdown file that we just created is converted to HTML with pandoc and stored in an R object. This R object is then manipulated and then written to an HTML file with the {varnish} website templates applied.\nWe use this function in the pull request workflows to demonstrate the changes in markdown source files, which is useful when package versions change, causing the output to potentially change."
  },
  {
    "objectID": "flow.html#build-site",
    "href": "flow.html#build-site",
    "title": "4¬† Flow Diagrams",
    "section": "4.5 build_site()",
    "text": "4.5 build_site()\nThe following sections will discuss the HTML generation (the following section), manipulation (the section after that), and applying the template (the final section) separately because, while these processes are each run via the internal sandpaper:::build_site() function, they are functionally separate.\n\n4.5.1 Generating HTML\nEach markdown file is processed into HTML via pandoc and returned to R as text. This is done via the internal function sandpaper:::render_html().\n\n\n\n\nsequenceDiagram\n    autonumber\n    box rgb(255, 214, 216) The Workbench\n    participant {sandpaper}\n    end\n    box rgb(230, 234, 240) Document Engine\n    participant pandoc\n    end\n    box rgb(255, 231, 168) Generated Files\n    participant site/built/episode.md\n    end\n\n    {sandpaper} --&gt;&gt; pandoc: LOAD pandoc with lua filters\n    site/built/episode.md --&gt;&gt; pandoc: READ markdown\n    pandoc --&gt;&gt; {sandpaper}: RENDER HTML as text\n\n\n\n\n\nFrom here, the HTML exists as the internal body content of a website without a header, footer, or any styling. It is nearly ready for insertion into a website template. The next section details the flow we use to tweak the HTML content.\n\n\n4.5.2 Processing HTML\nThe HTML needs to be tweaked because the output from pandoc, even with our lua filters, still needs some modification. We tweak the content by first converting the HTML into an Abstract Syntax Tree (AST). This allows us to programmatically manipulate tags in the HTML without resorting to using regular expressions.\nIn this part, we update links, images, headings, structure that we could not fix using lua filters. We then use the information from the episode to complete the global menu variable with links to the second level headings in the episode.\n\n\n\n\nsequenceDiagram\n    autonumber\n    box rgb(255, 214, 216) The Workbench\n    participant {sandpaper}\n    end\n    box rgb(230, 241, 255) R Object\n    participant HTML(AST)\n    end\n    box rgb(230, 234, 240) Helper Package\n    participant {xml2}\n    end\n\n    {sandpaper} --&gt;&gt; {xml2}: READ HTML\n    {xml2} --&gt;&gt; HTML(AST): PARSE HTML\n    activate {sandpaper}\n    note right of HTML(AST): sandpaper:::fix_nodes()\n    {xml2} --&gt;&gt; HTML(AST): update structure\n    HTML(AST) --&gt;&gt; {sandpaper}: extract menu items\n    note right of {sandpaper}: generate learner and instructor versions\n    deactivate {sandpaper}\n\n\n\n\n\n\n\n\n\n\n\nWorking With XML\n\n\n\nWorking with XML data is perhaps one of the strangest experiences for an R user because in R, functions will normally return a copy of the data, but when working with an XML document parsed by {xml2}, the data is modified in place.\nIt allows us to do neat things, but there is a learning curve associated.\n\n\n\n\n4.5.3 Applying Website Template\nNow that we have an HTML AST that has been corrected and associated metadata, we are ready to write this to HTML. This process is achieved by passing the AST and metadata to {pkgdown} where it performs a little more manipulation, applies the {varnish} template, and writes it to disk.\n\n\n\n\nsequenceDiagram\n    autonumber\n    box rgb(255, 214, 216) The Workbench\n    participant {sandpaper}\n    participant {varnish}\n    end\n    box rgb(230, 241, 255) R Object\n    participant HTML(AST)\n    end\n    box rgb(230, 234, 240) Helper Package\n    participant {pkgdown}\n    end\n    box rgb(255, 231, 168) Generated Files\n    participant site/docs/episode.html\n    end\n\n    activate {sandpaper}\n    {sandpaper} --&gt;&gt; {pkgdown}: Set global menu variables\n    HTML(AST) --&gt;&gt; {pkgdown}: Hand off HTML to pkgdown\n    deactivate {sandpaper}\n    activate {pkgdown}\n    {varnish} --&gt;&gt; {pkgdown}: Load template\n    {pkgdown} --&gt;&gt; site/docs/episode.html: WRITE website\n    deactivate {pkgdown}"
  },
  {
    "objectID": "sandpaper/intro.html#introduction",
    "href": "sandpaper/intro.html#introduction",
    "title": "5¬† The {sandpaper} package",
    "section": "5.1 Introduction",
    "text": "5.1 Introduction\n\nsandpaper (n.)\nHeavy paper coated on one side with sand or other abrasive material and used for smoothing surfaces.\n\nThe {sandpaper} package is the user interface for The Carpentries workbench and orchestrates the building and deployment of lessons. It helps lesson developers, authors, and maintainers to smooth out their contributions. Because of it‚Äôs user-facing and modular nature, it is the most complex package in The Workbench.\nPeople who want to use {sandpaper} will generally use it for one of these five things1:\n\nCreating lessons\nContributing to lessons\nMaintaining lessons\nRendering a portable lesson site\nRendering a lesson site with continous integration (GitHub Actions)\n\nImportantly, all of these points must be achievable by someone with little to no experience with R or any other programming language."
  },
  {
    "objectID": "sandpaper/intro.html#not-a-static-site-generator",
    "href": "sandpaper/intro.html#not-a-static-site-generator",
    "title": "5¬† The {sandpaper} package",
    "section": "5.2 Not a static site generator",
    "text": "5.2 Not a static site generator\nOne important distinction I would like to make is that {sandpaper} is not a static site generator. Yes, it may act like a static site generator because it creates static sites that are portable from markdown sources. However, it differs in that it is not intended to be as flexible as many other static site generators. This may seem like a negative point, but in the context of Carpentries Lessons, it is an asset.\nMany static site generators are extremely flexible at the cost of requiring the user to think deeply about the model of the website structure, deployment, and maintenance. For a single website, this is fine, but for distributed lessons like those in The Carpentries, it is much more difficult to use a static site generator because lesson maintainers should only have to focus on the content, not the mechanics or style. The {sandpaper} package builds lesson websites and nothing more. It is possible to use it for a narrative analysis, but at the end of the day, it will still be a lesson website."
  },
  {
    "objectID": "sandpaper/intro.html#you-had-one-several-jobs",
    "href": "sandpaper/intro.html#you-had-one-several-jobs",
    "title": "5¬† The {sandpaper} package",
    "section": "5.3 You had one several jobs",
    "text": "5.3 You had one several jobs\nIn terms of it‚Äôs relation to the other Workbench packages, {sandpaper} depends on {pegboard} to validate lessons, extract questions and timings for the schedule, and to extract the code handout. It relies on {varnish} to provide the HTML, CSS, and JS templates that create the websites via {pkgdown}. Its other dependencies are varied in purpose. It relies on other R packages and pandoc to do much of the work.\n\n5.3.1 Building Websites\nAt it‚Äôs core, {sandpaper} provides a workflow to process R Markdown to Markdown (if the lesson is purely markdown-based, then it Markdown is simply copied), generate HTML, and package that HTML content into a website framework with the following ideals:\n\nWhen processing R Markdown, the user‚Äôs environment should not be modified\nGenerated content should be auditable, but not part of the main git history\nProcesses for generating markdown, HTML, and the website should be modular such that if a better tool comes along, it can serve as a drop-in replacement\n\n\n\n\n\nflowchart TB\n    classDef default color:#383838,fill:#FFF7F1,stroke-width:1px\n    classDef external color:#383838,fill:#E6EEF8,stroke-width:1px\n    classDef normal color:#081457,fill:#E3E6FC,stroke-width:1px\n    classDef local fill:#FFC700,stroke:#333,stroke-width:1px\n    classDef remote fill:#D2BDF2, color:#201434,stroke-width:1px\n\n  subgraph Build Markdown\n  CR[\"{callr}\"]:::external\n  KT[\"{knitr}\"]:::external\n  RV[\"{renv}\"]:::external\n  LIB[\\\"renv/library\"/]:::external\n  MD[/\"markdown\"\\]:::local\n  end\n  \n  subgraph Render HTML\n  RMD[\"{rmarkdown}\"]:::external\n  pandoc([\"pandoc\"]):::default\n  HTML[(\"html (content)\")]:::local\n  end\n\n  subgraph Build Site\n  PD[\"{pkgdown}\"]:::external\n  VS[\"{varnish}\"]:::normal\n  SITE[/\"html (site)\"\\]:::remote\n  end\n\n  RMD -.-&gt;|provisions| pandoc\n  PD -.-&gt;|uses| VS\n  VS --&gt;|templates| SITE\n  MD --&gt;|input for| pandoc\n  pandoc --&gt;|outputs| HTML\n  CR -.-&gt;|loads| KT\n  CR -.-&gt;|loads| RV\n  RV -.-&gt;|provisions| LIB\n  LIB -.-&gt; KT\n  KT --&gt;|builds| MD\n  PD --&gt;|builds| SITE\n  HTML --&gt;|input for| PD"
  },
  {
    "objectID": "sandpaper/testing.html#introduction",
    "href": "sandpaper/testing.html#introduction",
    "title": "6¬† Testing {sandpaper}",
    "section": "6.1 Introduction",
    "text": "6.1 Introduction\n{sandpaper} is the largest package and the main user and deployment interface for The Workbench. The tests are all designed to work within a lesson context, which means a couple of things to be aware of.\n\nSome tests will take a long time to run. IO procedures are often one of the most time-consuming steps in computing and {sandpaper} does a lot of it.\nMost tests will be dependent on the previous tests in a file. Because the tests work on a folder on disk, we need to provision different scenarios of lesson state. It is far simpler to do this by side-effect rather than copying, setting up, and tearing down the state of the lesson for each and every test."
  },
  {
    "objectID": "sandpaper/testing.html#test-setup",
    "href": "sandpaper/testing.html#test-setup",
    "title": "6¬† Testing {sandpaper}",
    "section": "6.2 Test Setup",
    "text": "6.2 Test Setup\nThere is nothing that you as the contributor/developer need to do to set up for running these tests beyond what you have already done in your development setup. This section describes conceptually how {testthat} and {sandpaper} setup the testing environment after you run devtools::test().\nIn short, this is the process:\n\n{sandpaper} is loaded\nHelper test files are loaded\nThe setup script is loaded, which provisions the test lesson\nEach test file matchingtests/testthat/test-*.R is run, resetting the test lesson at the top of each file.\n\n\n6.2.1 Test Helpers\nSandpaper has three test helpers that handle some of the more tedious side-effects of testing.\n\nhelper-hash.R\n\nExpectation expect_hashed() that an episode file MD5 sum (expected) matches the MD5 sum (actual) we recorded in the site/built/md5sum.txt database.\n\nhelper-processing.R\n\nProvides an output string that demonstrates a screen output of a file being processed by {knitr}. This is used with expect_output().\n\nhelper-snap-transform.R\n\nA function that is passed to the transform parameter of expect_snapshot() and will mask the temporary directory path so that the snapshot does not continuously invalidate on every run.\n\n\n\n\n6.2.2 Setup Script\nThe first script to run is tests/testthat/setup.R, where a test lesson and a local git remote is created and stored in a temporary location for the duration of the test suite and a reset function is exposed for the tests."
  },
  {
    "objectID": "sandpaper/testing.html#conditionally-skipped-tests",
    "href": "sandpaper/testing.html#conditionally-skipped-tests",
    "title": "6¬† Testing {sandpaper}",
    "section": "6.3 Conditionally Skipped Tests",
    "text": "6.3 Conditionally Skipped Tests\nEach link below will open a code search for the different types of skipped tests in {sandpaper}\n\nskip_on_os\n\nThese are often tests that are skipped on Windows, usually for the reason that {renv} and filepaths behave slightly differently on Windows in a continuous integration setting.\n\nskip_if\n\nTests that are skipped under various conditions. For example, if Git is not installed on a system, we should not test any of the CI functions because they rely on Git.\n\nskip(\"&lt;for reasons&gt;\")\n\nThis pattern is more rare. It‚Äôs really useful in a situation where you are refactoring and know that a lot of tests will fail. If you sprinkle in these skips, you can focus on testing the core functionality of the refactor and then address the side-effects. Regarding the skips that remain: during testing, sometimes we encounter a ghost in the machine and we cannot set up the right conditions to run the test properly or the test was created with an earlier model of the package that we haven‚Äôt been able to shake. In these cases, instead of deleting the test or commenting out code, we add the skip() function and write a message of why we skipped it so if we need to come back to it later, we can."
  },
  {
    "objectID": "sandpaper/testing.html#continuous-integration",
    "href": "sandpaper/testing.html#continuous-integration",
    "title": "6¬† Testing {sandpaper}",
    "section": "6.4 Continuous Integration",
    "text": "6.4 Continuous Integration\n\n6.4.1 Package Cache\nRunning tests on Continuous Integration is tricky in part because we need to set up a {renv} package cache to work on Mac, Windows, and Linux systems. In practise, we have to set up a specific RENV_PATHS_ROOT folder for each system.\n\n6.4.1.1 Windows\nFor Windows, the setup is even more complex because there are weird caveats in how pandoc and {renv} work on the CI version of Windows.\n\n\n\n6.4.2 Dependencies\nAt the moment, we test the current versions of dependencies when we are running tests in the test-coverage.yaml file. For the R-CMD-check.yaml file, however, we test the development version of {renv}. The reason why we do this is because in March 2023, {renv} 0.17.0 was released and subsequently broke bioconductor-based R Markdown lessons and new R Markdown lessons that needed to be bootstrapped (see sandpaper#406).\nThis can lead to a situation where the tests will pass on the test coverage check, but fail for R CMD check, which is diagnostic because it tells us that there is an upstream issue in {renv} that we can address before it becomes a problem after a CRAN release."
  },
  {
    "objectID": "sandpaper/package-cache.html#introduction",
    "href": "sandpaper/package-cache.html#introduction",
    "title": "7¬† The R package cache",
    "section": "7.1 Introduction",
    "text": "7.1 Introduction\nAll lessons that use The Workbench can build using either Markdown or R Markdown file formats. The R package cache allows for R Markdown file formats to be built reproducibly and consistently. The cache is expected to be mindful of these formats in the following ways (as taken from Building Lessons With A Package Cache):\n\nreliable setup: the version of the lesson built on the carpentries website will be the same as what you build on your computer because the packages will be identical\nenvironmentally friendly: The lesson dependencies are NOT stored in your default R library and they will not alter your R environment.\ntransparent: any additions or deletions to the cache will be recorded in the lockfile, which is tracked by git.\n\nThe package cache is only used when building lessons with R Markdown elements and performs the folowing tasks in a separate R session to avoid polluting the user‚Äôs environment:\n\nBefore markdown is built: We check for consent to use the package cache with sandpaper:::renv_check_consent() and then provision any packages needed for the lesson with sandpaper::manage_deps()\n\n\n\n\n\n\nDependency Tree for renv_check_consent()\n\n\n\n\n\nThe renv_check_consent() checks if the user has run sandpaper::use_package_cache(), which allows {renv} to create and maintain a global package cache on their system.\n\n\n\n\nDuring each markdown rendering: If we have consent, we load the {renv} profile to reproducibly render the markdown document\n\n\n\n\n\n\nFlow Diagram for build_episode_md()\n\n\n\n\n\nThis flow represents the build process for each R Markdown file. This function is called from within a separate R process. The only conditional here determines if the {renv} environment needs to be loaded.\n\n\n\n\n\nThis chapter will go into the history of using a package cache in Carpentries lessons, dig into the design principles, and understand challenges for moving forward."
  },
  {
    "objectID": "sandpaper/package-cache.html#a-bit-of-history",
    "href": "sandpaper/package-cache.html#a-bit-of-history",
    "title": "7¬† The R package cache",
    "section": "7.2 A Bit of History",
    "text": "7.2 A Bit of History\nAs of this writing, The Workbench is able to reproducibly build and deploy lessons across machines and infrastructures thanks to the package cache provided by {renv}, but it is important to understand how we got here and what the motivations were, because the tools we have now simply did not exist in 2016. This section dives a bit into the history of writing R markdown content in Carpentries lessons and what lessons‚Ä¶ were learned.\nSoftware Carpentry Lessons have been able to handle content written in R Markdown since July 2014. This process was disrupted in June 2016 with the release of the new styles template, but luckily, Fran√ßois Michonneau swooped in to the rescue by providing a templating setup that would not only render the Markdown, but keep the output separate. The very next month, Fran√ßois submitted carpentries/styles#83, which added the capability to automatically detect and install packages needed to build an R-based lesson.\nOf course, back in 2016, in order to deploy an R-based lesson, you still had to build it locally, which sounds simple until you consider the aspect of reproducibility (Marwick 2016; Wilson et al. 2017). If you build the same document on two different machines, there is no guarantee that you will get the same results. Thus, in May 2018, Raniere Silva added the ability to build R-based lessones on Continuous Integration. Finally, in 2020, Maxim Belkin added GitHub Workflows to the styles repository so that we no longer had to rely on TravisCI.\nThese changes allowed a single, definitive source for lessons to be built, but alas, they still were not reproducible because the packages used to build the lesson were always being run with the most recent versions. This lead to problems with outputs changing or worse, the entire build failing (see swcarpentry/r-novice-gapminder#746. Moreover, lesson maintainers of thes R lessons encountered the following problems:\n\nEvery time they built their lessons locally, their default R package library would update. This was especially a problem for maintainers who were working on their dissertations and really could not afford to lose work due to their packages changing.\nMaintainers were unsure of what would happen to the lesson with any given pull request and would have to manually run the results or trust the contributor.\nAll the normal struggles with Jekyll.\n\nReproducibility is hard. Software ecosystems are always shifting like the sand dunes in the Sahara (Vaniea and Rashidi 2016). By late 2020, we had come a long way in terms of automating the build process for R-based lessons, but there were still many hills to climb. It was in this context that we developed the use of {renv} and the R package cache to automate package provisioning, caching, and auditable updating so that R-based lessons could reliably be deployed with no surprises."
  },
  {
    "objectID": "sandpaper/package-cache.html#design-principles",
    "href": "sandpaper/package-cache.html#design-principles",
    "title": "7¬† The R package cache",
    "section": "7.3 Design Principles",
    "text": "7.3 Design Principles\nIt is worth reading through carpentries/sandpaper#21 to see the discussion and thoughts around the origin of the design for using this feature. It was implemented during a three week period between 2021-08-24 and 2021-09-16, as detailed in the pull request carpentries/sandpaper#158.\nIt‚Äôs easy to think about a package cache as a way to declare dependencies for a lesson in a reproducible way, but it‚Äôs more than that. The philosophy of R packages on CRAN is that they all need to work with the latest versions of each other, so a lesson that teaches R should be reasonably up-to-date. Thus, any given package must be able to do the following four things in the package cache:\n\nenter the package cache and record the version number\nexit the package cache and be removed from the record\nupdate to the latest version\npin to a specific version\n\nEvery good tool for handling a package cache does these four things, and the workflow to add a new package with {renv} (before version 1.0.0) flows like this:\n\nContributor A would like to add {packageA} to the project\nContributor A opens the project and installs {packageA}\nContributor A adds {packageA} to the project content\nContributor A takes a snapshot of the project to the lockfile\n\nIn this scenario, Contributor A must explicitly install the package to the project before they can use it regardless of whether or not they have that package on their system. Steps 2 and 4 of this workflow involve explicitly working with the package cache and, in my experience, R users will often jump directly to step 3, which leads to failed builds and frustration.\nWhen designing a user interface, you also need to think about what distractions and real-life stressors the lesson maintainer/developer/contributor is potentially dealing with. You want to minimize the amount of fuss that the contributor needs to do to get something working. A contributor should only have to add a package once to the lesson content to make it available. This means that the following steps are taken to add a new package:\n\nContributor A has {packageA} in their library and wants to demonstrate the use of {packageA} in the lesson.\nContributor A inserts a code block in the lesson that declares library(\"packageA\") or packageA::fun() somewhere in the code block:\n\n```{r}\n# load the packageA package\nlibrary(\"packageA\")\n```\n\n\nAfter that, when the lesson is built, {packageA} is automatically added to the lockfile. If Contributor A decideds to no longer use {packageA}, they can remove it from the lesson content and the next build will remove {packageA} from the lockfile. In this way, the lesson content remains the source of truth for the packages used in the lesson and the lockfile represents the metadata associated with the lesson.\nThat means the following WRT to packages in a lesson:\n\nUsers should not have to know that the lockfile exists\nThe packages used in the lesson should be locked to specific versions and be reproducible across machines\nThe packages used in the lesson should not overwrite the packages in the user‚Äôs default R library\nAny package that is missing from the user‚Äôs machine should automatically be provisioned\nAll packages used should be the correct version\nThe lockfile should be auditable\nThe lockfile defining the package versions should update/remove packages according to the contents of the lesson\nUsers should be able to specify versions in the lockfile easily\nUsers should be able to automatically update the lockfile\n\n\n\n\n\nMarwick, Ben. 2016. ‚ÄúComputational Reproducibility in Archaeological Research: Basic Principles and a Case Study of Their Implementation.‚Äù Journal of Archaeological Method and Theory 24 (2): 424‚Äì50. https://doi.org/10.1007/s10816-015-9272-9.\n\n\nVaniea, Kami, and Yasmeen Rashidi. 2016. ‚ÄúTales of Software Updates.‚Äù Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems, May. https://doi.org/10.1145/2858036.2858303.\n\n\nWilson, Greg, Jennifer Bryan, Karen Cranston, Justin Kitzes, Lex Nederbragt, and Tracy K. Teal. 2017. ‚ÄúGood Enough Practices in Scientific Computing.‚Äù Edited by Francis Ouellette. PLOS Computational Biology 13 (6): e1005510. https://doi.org/10.1371/journal.pcbi.1005510."
  },
  {
    "objectID": "pegboard/intro.html#introduction",
    "href": "pegboard/intro.html#introduction",
    "title": "8¬† The {pegboard} package",
    "section": "8.1 Introduction",
    "text": "8.1 Introduction\nThe {pegboard} package was the very first package written for The Carpentries Workbench. It‚Äôs initial purpose was to parse the lessons based on the styles lesson infrastructure to figure out how lesson authors and maintainers were using the challenges and solutions. You can see this analysis in a vignette I started in May 2020 1.\nIt‚Äôs purpose now is two-fold:\n\nparse and validate the lessons for structural markdown elements\ntranslate Carpentries-style materials from the styles lesson infrastructure (Jekyll-based) to The Workbench (Pandoc-based)\n\n\n8.1.1 Dependencies\nThe dependency footprint of {pegboard} is intended to be small. The package is intended for validation and translation. It is meant to be stable.\nPegboard was built on top of the [{tinkr}] package, intially developed by Ma√´lle Salmon (rOpenSci) and now maintained by Zhian Kamvar. This package uses the CommonMark C library to parse Markdown into XML and then uses a custom XSLT stylesheet to translate Markdown back to XML. One of the key advantages that CommonMark‚Äôs XML gives us is the ability to extract line numbers and positions for markdown elements, which allows us to accurately report any Markdown issues to the user.\nThe objects used in pegboard are created with the [{R6}] package, which implements encapsulated object orientated programming for R. This style of programming is very similar to that of Python or Java. One of the reasons why we use {R6} is because objects created in this system are modified in place by their methods. This is important because the package to manipulate XML data, [{xml2}], is built directly on top of the libxml2 C library, which also modifies objects in place, but it‚Äôs not inherently obvious when you work with them, so having a formal system like {R6} to encapsulate them makes more sense than a functional programming framework."
  },
  {
    "objectID": "varnish/intro.html#introduction",
    "href": "varnish/intro.html#introduction",
    "title": "9¬† The {varnish} package",
    "section": "9.1 Introduction",
    "text": "9.1 Introduction\nThe {varnish} package is a weird little package in that it does not contain any actual R code. It‚Äôs purpose is to host HTML templates along with the CSS and JavaScript needed to display the lesson.\nWe take advantage of the fact that the only thing actually required to install an R package is the presence of a DESCRIPTION file1. These all live inside the inst/ folder, which is a place that allows files to be installed along with the package.\nThe {pkgdown} package uses this as a mechanism for package developers to override the default styling, creating customized documentation websites such as the rOpenSci documentation sites: https://docs.ropensci.org/rotemplate/.\nThis allows people to update the lesson styling however they wish2 and while we could include it in {sandpaper}, it‚Äôs best kept separate so that people can update {varnish} without needing to update the entire tool suite."
  },
  {
    "objectID": "varnish/intro.html#design-and-implementation-background",
    "href": "varnish/intro.html#design-and-implementation-background",
    "title": "9¬† The {varnish} package",
    "section": "9.2 Design and Implementation Background",
    "text": "9.2 Design and Implementation Background\nThe design for the frontend was created by Emily de la Mettrie in 2021 after consultation with Zhian N. Kamvar and Fran√ßois Michonneau using examples from The Unix Shell and parts of Exploring Data Frames for content cues.\nThe final figma design project3 was then handed off to a team at Bytes.co, who translated the designs to CSS and JavaScript, subcontracted an a11y testing company to interactively test the prototype for a11y issues.\nThe prototype we recieved from Bytes.co was a Jekyll template serving HTML files. Zhian created a staging repository called shellac to transform the site from one that was served via static site generator to one that was standalone. The preview is preserved at https://zkamvar.github.io/shellac/student_carpentries.html.\nThis site was then stripped of the added into {varnish} in carpentries/varnish#14 between 2022-01-10 and 2022-01-24, when the 1.0.0 release of {varnish} was created and the sandpaper docs website was updated to use the new version of the HTML, CSS, and JavaScript."
  },
  {
    "objectID": "releases.html#background",
    "href": "releases.html#background",
    "title": "10¬† Release Process for Workbench Packages",
    "section": "10.1 Background",
    "text": "10.1 Background\nThe workbench contains three main packages:\n\n{sandpaper}: user interface and workflow engine\n{pegboard}: parsing and validation engine\n{varnish}: HTML templates, CSS, and JS elements\n\nEach of these packages are available on the Carpentries R-Universe and new versions are checked for hourly. This allows folks to get up-to-date versions of The Workbench packages built for their system without running out of GitHub API query attempts.\nIn order to maintain quality, packages are only sent to the R-Universe if they have been formally released on GitHub (as specified in the packages.json configuration file). This allows us to incrementally add new experimental features without changing the stable deployments."
  },
  {
    "objectID": "releases.html#release-process",
    "href": "releases.html#release-process",
    "title": "10¬† Release Process for Workbench Packages",
    "section": "10.2 Release Process",
    "text": "10.2 Release Process\nWhen a package is ready for release we use the following checklist:\n\nUpdate version number in DESCRIPTION\nAdd NEWS for the changes in this version\nEnsure all changes are committed and pushed\nadd new signed tag with the name ‚Äú X.Y.Z‚Äù\n# example: create a signed (-s) tag for sandpaper 3.3.3\ngit tag -s 3.3.3 -m 'sandpaper 3.3.3'\ncreate a release on github from the new tag\n\n\n\n\n\n\n\nNote\n\n\n\nZhian likes to create tags via the command line because he has set up his git configuration to use a gpg signature so the tags and the releases are both verified.\n\n\nThe last two items can be achieved in a single step with the github cli with the command gh release create X.Y.Z for the version number\ngh release create 3.3.3\n# ? Title (optional) sandpaper 3.3.3\n# ? Release notes  [Use arrows to move, type to filter]\n#   Write my own\n# &gt; Write using generated notes as template\n#   Leave blank\nSelecting ‚ÄúWrite using generated notes as a template‚Äù opens an editor and populates it with the pull requests that have been accepted since the last release.\nOnce the relase is created on GitHub, then the package will be available on the R-Universe in about an hour or less."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "11¬† Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Marwick, Ben. 2016. ‚ÄúComputational Reproducibility in\nArchaeological Research: Basic Principles and a Case Study of Their\nImplementation.‚Äù Journal of Archaeological Method and\nTheory 24 (2): 424‚Äì50. https://doi.org/10.1007/s10816-015-9272-9.\n\n\nVaniea, Kami, and Yasmeen Rashidi. 2016. ‚ÄúTales of Software\nUpdates.‚Äù Proceedings of the 2016 CHI Conference on Human\nFactors in Computing Systems, May. https://doi.org/10.1145/2858036.2858303.\n\n\nWickham, Hadley, and Jennifer Bryan. 2023. ‚ÄúR\nPackages (2e).‚Äù https://r-pkgs.org/.\n\n\nWilson, Greg, Jennifer Bryan, Karen Cranston, Justin Kitzes, Lex\nNederbragt, and Tracy K. Teal. 2017. ‚ÄúGood Enough Practices in\nScientific Computing.‚Äù Edited by Francis Ouellette. PLOS\nComputational Biology 13 (6): e1005510. https://doi.org/10.1371/journal.pcbi.1005510."
  },
  {
    "objectID": "sop.html#get-a-reproducible-example",
    "href": "sop.html#get-a-reproducible-example",
    "title": "Appendix A ‚Äî Standard Operating Procedures",
    "section": "A.1 Get a Reproducible Example",
    "text": "A.1 Get a Reproducible Example\nThe most powerful tool in the developer‚Äôs toolbox for demonstrating an an issue or a new feature is the reproducible example. It is no surprise that Jenny Bryan (of ‚ÄúEverything I Know Is From Jenny Bryan‚Äù fame) is the maintainer of the {reprex} package and has an incredibly useful webinar on how to create reproducible examples with {reprex}.\n\n\n\n\n\n\nSystem-Dependent Issues\n\n\n\nThere are times when you cannot create a reproducible example that will produce the results you want to see. This is often the case when there is a system-dependent issue. In these cases, you should share the reprex with someone who has the system in question and have them run it."
  },
  {
    "objectID": "sop.html#sec-git-etiquitte",
    "href": "sop.html#sec-git-etiquitte",
    "title": "Appendix A ‚Äî Standard Operating Procedures",
    "section": "A.2 Git/GitHub Etiquitte",
    "text": "A.2 Git/GitHub Etiquitte\nIn The Workbench practice, commits are never pushed to the main branch of the packages. All issues and features are fixed/made by pull requests because they give a better accounting of what was changed and why. Using this, it is good to strive for these practises1:\n\nIf an issue for the feature/bug does not exist, create it with documentation about where the error exists (or where the feature should be). Use the ‚Äúcopy permalink‚Äù when you click on a line number in the source view of GitHubto create a preview of the code as it existed before the feature/fix.\ncreate a new branch from main that describes the purpose and includes the issue number. For example: avoid-gert-config-449 removed a bit of code that was using the {gert} package to check for a git user, which was unnecessary.\npush the branch to GitHub2 and create a new draft pull request\nAdd a test that will reproduce the bug (if possible) before any code\nCOMMIT OFTEN. There are MANY times when I have been working on a feature deeply and have forgotten to commit, only to lose track of what changes I made and why3. Remember that git is your lab notebook.\nIterate writing code and committing until the tests for that particular function passes.\nWrite a new item in NEWS and bump the version in DESCRIPTION.\nPush to GitHub and mark as ready for review; tag @carpentries/maintainers-workbench\n\n\nA.2.1 Pull Request Reviews\nWhile The Workbench was being rapidly developed by Zhian Kamvar, all pull requests were merged by Zhian, even if he created them. After the launch of The Workbench across all official lessons, The Workbench Maintainer Group will now review all pull requests. In order to ensure pull request reviews are equitably given, please read Alex Hill‚Äôs blog post entitled ‚ÄúThe Art of Giving and Receiving Code Reviews‚Äù."
  },
  {
    "objectID": "sop.html#addressing-issues",
    "href": "sop.html#addressing-issues",
    "title": "Appendix A ‚Äî Standard Operating Procedures",
    "section": "A.3 Addressing Issues",
    "text": "A.3 Addressing Issues\nOne big challenge with issues is that you cannot know where the issue is coming from. If you do nothing else, please watch this Keynote talk from Jenny Bryan: Object of type ‚Äòclosure‚Äô is not subsettable. This will give you the right mindset for broadly approaching issues in R package development, which can be summarised as:\n\nTurn it off and on again (Restart R in a clean session)\nMake a reprex\nDig into the error (via traceback() and/or a debugger)\nFuture-proof your fixes and make things within reach\n\nWith these tools, if you cannot reproduce the error, you can guide the user to give you the information you need to reproduce the error and then you can follow the git guidelines to iterate on the fix.\n\n\n\n\n\n\nThink of the big picture\n\n\n\nAs you are fixing an issue, consider the larger picture of the issue. Sometimes you will run into an issue that will technically fix it, but still leave the possibility for future issues to open up. The most important thing is to document what future work needs to be done to ensure a robust solution while it is still fresh in your mind. This can be in an issue or in the comments of the code itself.\nSometimes an issue is urgent enough that a quick fix is what is needed, and in those cases, it‚Äôs best to open up a followup issue that addresses what would be needed for a more robust fix. Sometimes the solution is splitting a large function into smaller functions, but other times it may be a refactor of the internal data structure."
  },
  {
    "objectID": "sop.html#creating-new-features",
    "href": "sop.html#creating-new-features",
    "title": "Appendix A ‚Äî Standard Operating Procedures",
    "section": "A.4 Creating New Features",
    "text": "A.4 Creating New Features\nIf you want to create a new feature, the most important thing to do is to clearly define the audience, scope, dependencies, inputs and the outputs of the feature that you want to create. It‚Äôs best to strive for new features that bolster existing features (e.g.¬†sandpaper::serve() provides an continously updating version of sandpaper::build_lesson()) or those that are modular and optional (e.g.¬†the fail_on_error config option for lessons using R Markdown force an error in code blocks to stop the lesson from rendering unless those code blocks have the error = TRUE option).\nOne of the most important things to consider when adding new features is the maintenance and deployment workflow. Maintainers and contributors should not need to worry about function arguments, GitHub Actions, or new Markdown syntax in order to implement a new feature that will be deployed automatically to all of the lessons. A new feature should not break their workflow or the deployment workflow.\n\n\n\n\n\n\nSimple Example\n\n\n\nAs an example, when we were discussion folder organistaion, The original config template had a ‚Äúschedule‚Äù section instead of ‚Äúepisodes‚Äù. When I replaced ‚Äúschedule‚Äù with ‚Äúepisodes‚Äù, I added functionality to allow for old-style lessons to move forward so that any existing test lessons did not break. To this day, you can still create a lesson using schedule instead of episodes as the keyword."
  },
  {
    "objectID": "flight-rules.html#sec-within",
    "href": "flight-rules.html#sec-within",
    "title": "Appendix B ‚Äî Examples and Flight Rules",
    "section": "B.1 Within The Workbench R Packages",
    "text": "B.1 Within The Workbench R Packages\nBugs or features in this category are entirely within our control and are theoretically the easiest/most quick implementations. Items in this category can be split into either single package items which can be fixed with a single pull request or cross-package items, which require coordination of pull requests to achieve.\n\nB.1.1 Single Package\nIn this section, we outline issues that are addressed within a single package. Note that this does not indicate that these issues are straightforward to address.\n\nB.1.1.1 Single-Function Issues\nIf you are here, you have determined that the bug or feature that you are working on will affect a single function or data pathway. These issues are often the most straightforward to address. Below, I‚Äôve documented narratives for these issues.\n\nMarkdown file for 404 page created with read-only permissions\n\ns479 Situation\n\nIssue: carpentries/sandpaper#479\nResolver: zkamvar\nType: Local\nOS: Rocky Linux 8.8\nPackage: sandpaper\n\nThe user is attempting to build a lesson, but they are unable to because an error appears during the ‚ÄúCreate 404 page‚Äù step:\n‚îÄ‚îÄ Creating 404 page ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nError in file(file, ifelse(append, \"a\", \"w\")) : \n  cannot open the connection\nIn addition: Warning messages:\n[snip]\n7: In file(file, ifelse(append, \"a\", \"w\")) :\n  cannot open file '/tmp/RtmpmaiZ5B/file73cdc48b90540.md': Permission denied\n\n\ns479 Diagnosis\nThis permissions issue was a problem with copying a read-only file without adjusting the subsequent permissions. It stemmed from build_404() calling render_html() with the presence of a links.md document at the top of the lesson. Packages in the user‚Äôs R library are installed by the systems administrator and the user does not have permissions to write or append any file in that folder. When build_404() runs, it passes a template markdown file to render_html(). If there is an option called sandpaper.links set to a filepath, then this function will copy the input file to a temporary file and append the links to that temporary file before rendering it to HTML. Because the input file was read-only, copying the file to the temporary directory retained its permissions and we were unable to append the links.\n\n\ns479 Solution\nPull Request: carpentries/sandpaper#482\nThe solution was to add a single line adding user write permissions before the links file was appended: fs::file_chmod(tmpin, \"u+w\").\n\n\ns479 Alternative Solution\nThis additionally could have been avoided by temporarily unsetting the sandpaper.links option for the build_404() function before it calls render_html(). This would prevent it entering the loop where it appends the links, making the process slightly faster. The only downside is that we would need to do that for all of the other templated pages (though I believe that might be the only one).\n\n\ns479 Narrative\n\nIssue: carpentries/sandpaper#479\nFirst impression: this is running on a version of Linux that Zhian does not know anything about. My thoughts are that it will be a difficult fix.\nI suspect the bug might be due to the {fs} package and ask for the user if they could test out the following code snippet:\ntmp &lt;- fs::file_temp(ext = \".md\")\ncat(\"test\\n\", file = tmp, append = TRUE)\nreadLines(tmp)\nI looked again did not recognise the code snippet where the issue seemed to be (file(file, ifelse(append, 'a', 'w'))) - so this seems to be a problem with a non-Workbench package.\ninitially went looking for this code in the fs package, but GitHub search showed that this code doesn‚Äôt appear there either.\nnext guess is the cat function, which is used to add link references to the end of files. I searched the R code base and found the snippet in the cat()function\nthat seemed to be where that code snippet was coming from, but the problem really originated a few lines above the call to cat: when the template for the 404 page (which is saved where the package was installed) is copied‚Äîfile_copy() copies a file and all of its permissions‚Äîso the copy is read-only for non-admin users.\nI opened a PR to test for the error, then applied a fix to prevent it from being thrown again.\nAsked the reporter to install the patch on their system and report back on whether it worked.\nThey reported back that it did‚Äîand pointed out a typo!\nAfter merging PR, create a new release (see process in The Release Workflow)\n\n\n\n\n\nB.1.1.2 Multi-Function Issues\n\n\nB.1.1.3 Test Failures With No User Impact\n\n\n\nB.1.2 Aross Packages"
  },
  {
    "objectID": "flight-rules.html#sec-upstream",
    "href": "flight-rules.html#sec-upstream",
    "title": "Appendix B ‚Äî Examples and Flight Rules",
    "section": "B.2 Upstream R Packages",
    "text": "B.2 Upstream R Packages\n\nB.2.1 renv\n\nB.2.1.1 Background\nThe {renv} package is a key player for allowing {sandpaper} to provision and maintain the R packages required to build R-based lessons. The motivation and strategy for how it works can be found in the Building Lessons With A Package Cache article in the {sandpaper} docuementation.\nIt‚Äôs worth diving into carpentries/sandpaper#21 to see the discussion and thoughts around the origin of the design for using this feature. It was implemented during a three week period between 2021-08-24 and 2021-09-16, as detailed in the pull request carpentries/sandpaper#158.\n\n\nB.2.1.2 In practices\nWe have to consider {renv} in practice from the standpoint of both local computers and on GitHub, which can behave very differently and require different tools to address their tasks.\nThere are three tools and packages that use {renv}:\n\n{sandpaper} is designed to provide a way to manage dependencies in a lesson\n{vise} was originally intended as a project to split out {sandpaper} code that used {renv} to simplify the testing. At the moment, it provides utilities for automatically provisioning C libraries on Ubunutu Linux and running the equivalent of sandpaper::update_cache() in a GitHub Actions context.\ncarpentries/actions these contain R code within YAML files üò± that will call {renv} and {vise}.\n\n\n\nB.2.1.3 Debugging Tips\n\nB.2.1.3.1 Setting up a reproducible environment\nBrowse the {renv} issues opened by @zkamvar. In nearly all of these issues, I provide a reproducible example. They generally follow the pattern of:\n\ncreate a temporary file\nmake it a directory and move there\nadd any files that are needed before the renv project is set up (if specific to problem)\nset up a {renv} project with renv::init()\ndemonstrate problem\n\ntmp &lt;- tempfile()\ndir.create(tmp)\nsetwd(tmp)\nwriteLines(\"library(R6)\", \"test.R\")\nrenv::init(profile = \"test\")\n# demonstrate problem here\n\n\nB.2.1.3.2 Choosing a minimal example\nPresenting a failing CI run with a Workbench lesson is reproducible, but it‚Äôs not minimal. Presenting the same with a smaller lesson is still not minimal. Often times, the issue involves detecting and installing a new package. In this case, you want to choose a package that has few to no dependencies and is not listed as a dependency for knitr. One example that I use often is the {cowsay} package. It has a total of three dependencies and is not depended on by anything. If I need a quick package with zero dependencies, I will reach for {R6} or {aweek}. Both of these packages are under 100 Kilobytes, are pure R code, do not have any dependencies, and do not require compillation.\n\n\nB.2.1.3.3 When you just can‚Äôt reproduce it locally\nThere have been times when {renv} seems to fail only on GitHub Actions. This was the case for {renv} version 0.17.0, as I reported in rstudio/renv#1161.\nThe important thing in these situations is to stay calm and try to narrow down as much as possible the exact conditions that will create the problem. Once you have those, you can open an issue on the {renv} issue tracker. If you are at this point, it‚Äôs important to not expect this to be resolved quickly, because it is likely out of your control. The best you can do is to try the debugging techniques that Kevin provides and report back on the issue thread.\nOnce the issue is resolved: Thank Kevin for his help. This is a very important point. Maintainers often only hear from their users if somehting is going wrong, so it‚Äôs important to let them know that they are appreciated."
  },
  {
    "objectID": "flight-rules.html#sec-actions",
    "href": "flight-rules.html#sec-actions",
    "title": "Appendix B ‚Äî Examples and Flight Rules",
    "section": "B.3 GitHub Actions",
    "text": "B.3 GitHub Actions"
  },
  {
    "objectID": "flight-rules.html#sec-structural",
    "href": "flight-rules.html#sec-structural",
    "title": "Appendix B ‚Äî Examples and Flight Rules",
    "section": "B.4 Structural Features",
    "text": "B.4 Structural Features"
  }
]