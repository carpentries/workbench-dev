[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Workbench Developer’s Guide",
    "section": "",
    "text": "Preface\nThe Carpentries Workbench is a open-source and portable lesson infrastructure built with the R programming language. Despite it being built in R, contributors do not need to know any R in order to use it to build reliable, stylish, and accessible lessons.\nThis book serves as development documentation for The Carpentries Workbench. It was written between June and December 2023 primarily to orient new developers and contributors to The Workbench ecosystem.\n\n\n\n\n\n\nPrerequisite\n\n\n\nThis book assumes familiarity with R Package Development. If you are unfamiliar, please read R Packages (2e) (Wickham and Bryan 2023).\n\n\n\n\n\n\nWickham, Hadley, and Jennifer Bryan. 2023. “R Packages (2e).” https://r-pkgs.org/."
  },
  {
    "objectID": "intro.html#building-lessons",
    "href": "intro.html#building-lessons",
    "title": "1  Introduction",
    "section": "1.1 Building Lessons",
    "text": "1.1 Building Lessons\nIn a broad sense, this is what happens when you run sandpaper::serve() or sandpaper::build_lesson(). The interaction between the three Workbench packages, the lesson content, and the author can be summarised like this where the author makes an edit:\n\n\n\n\n\n\nSummary Content\n\n\n\nThis content is a general picture of what happens between the packages. For a more in-depth discussion and more detailed diagrams, please visit the Flow Diagrams page.\n\n\n\n\n\n\nsequenceDiagram\n    autonumber\n    actor Author\n    participant Lesson \n    box rgb(255, 214, 216) The Workbench\n    participant {sandpaper}\n    participant {pegboard}\n    participant {varnish}\n    end\n\n    Author -&gt;&gt; {sandpaper}: sandpaper::serve()\n    activate Author\n    {sandpaper} --) Author: website preview\n    note left of {sandpaper}: monitor for changes\n    Author -&gt;&gt; Lesson: make an edit\n    deactivate Author\n    Lesson --&gt;&gt; {sandpaper}: READ changed file(s)\n    {sandpaper} --&gt;&gt; {pegboard}: validate Lesson\n    activate {pegboard}\n    note left of {sandpaper}: provision global menu elements\n    {pegboard} --) Author: report accessibility \n    deactivate {pegboard}\n    activate {sandpaper}\n    note left of {sandpaper}: WRITE markdown\n    {varnish} --&gt;&gt; {sandpaper}: load and apply website template\n    note left of {sandpaper}: WRITE website\n    {sandpaper} --) Author: website preview\n    deactivate {sandpaper}\n\n\n\n\n\nIn terms of folder structure, the workflow runs the two-step workflow to first render markdown files into site/built and then uses those files to render the HTML, CSS, and JavaScript into site/built. These workflows are detailed in The Workflows Chapter.\n\n\n\n\nflowchart TB\n    classDef default color:#383838,fill:#FFF7F1,stroke-width:1px\n    classDef external color:#383838,fill:#E6EEF8,stroke-width:1px\n    classDef normal color:#081457,fill:#E3E6FC,stroke-width:1px\n    classDef local fill:#FFC700,stroke:#333,stroke-width:1px\n    classDef remote fill:#D2BDF2, color:#201434,stroke-width:1px\n\n    SERVE(\"serve()\"):::normal\n    BLESS(\"build_lesson()\"):::normal\n\n    subgraph \"Core Workflow\"\n    BUILT[\"site/built\"]:::local\n    SITE[\"site/docs\"]:::local\n    VLESS(\"validate_lesson()\"):::normal\n    BUILDMD([\"build_markdown()\"]):::normal\n    BUILDSITE([\"build_site()\"]):::normal\n    end\n\n    %%BUILT ~~~ SITE\n\n    SERVE --&gt; BLESS\n    %% SERVE ~~~ VLESS\n    %% SERVE ~~~ BUILDMD\n    BLESS --&gt; VLESS\n    VLESS -.- BUILDMD\n    BLESS --&gt; BUILDMD\n    BUILDMD --&gt; BUILT\n    BUILT -.- BUILDSITE\n    VLESS -.- BUILDSITE\n    BLESS --&gt; BUILDSITE\n    BUILDSITE --&gt; SITE\n\n\n\n\n\n\n\n\n\n\n\nResource folder names\n\n\n\nThe names of the folders inside site/ are considered internal resources and they can change at any time. The reason why the folder for the final website output is called site/docs/ is because we use the {pkgdown} package to provision the website without needing to bundle the templates inside of {sandpaper}, but we never got around to explicitly changing the name of that folder.\n\n\nThe site/docs folder contains the full website that can be safely used offline. This is the core of the workflow and is used both locally and in a remote setting. The only difference with the remote setting is that we use a few Git tricks to provision the markdown cache without needing to store it in the default branch."
  },
  {
    "objectID": "intro.html#building-lessons-on-github",
    "href": "intro.html#building-lessons-on-github",
    "title": "1  Introduction",
    "section": "1.2 Building Lessons on GitHub",
    "text": "1.2 Building Lessons on GitHub\nIn the remote workflow, we still use the same workflow as above, except now we use ci_deploy() to link the branches and folders using worktrees, which you can think of as Git branches assigned to separate folders.\n\n\n\n\nflowchart TB\n    classDef default color:#383838,fill:#FFF7F1,stroke-width:1px\n    classDef external color:#383838,fill:#E6EEF8,stroke-width:1px\n    classDef normal color:#081457,fill:#E3E6FC,stroke-width:1px\n    classDef local fill:#FFC700,stroke:#333,stroke-width:1px\n    classDef remote fill:#D2BDF2,stroke:#201434,stroke-width:1px\n    classDef notouch fill:#F99697,stroke:#A4050E,stroke-width:1px\n\n\n    GH[(\"@main\")]:::remote\n    MDOUT[(\"@md-outputs\")]:::notouch\n    PAGES[(\"@gh-pages\")]:::notouch\n    DEPLOY([\"ci_deploy()\"]):::external\n    CIBUILDMD([\"ci_build_markdown()\"]):::external\n    CIBUILDSITE([\"ci_build_site()\"]):::external\n\n    subgraph GitHub Actions Runner\n    REPO[\"[repo]\"]:::local\n    BUILT[\"[repo]/site/built\"]:::local\n    SITE[\"[repo]/site/docs\"]:::local\n    VLESS(\"validate_lesson()\"):::normal\n    BUILDMD([\"build_markdown()\"]):::normal\n    BUILDSITE([\"build_site()\"]):::normal\n    end\n\n\n    GH ---&gt; REPO\n    GH ~~~ DEPLOY\n    REPO -.- VLESS\n\n\n    DEPLOY ---&gt; VLESS\n    DEPLOY ---&gt; CIBUILDMD\n    DEPLOY ---&gt; CIBUILDSITE\n    VLESS -.- BUILDMD\n    CIBUILDMD ---&gt; MDOUT\n    MDOUT &lt;-.-&gt; BUILT\n    CIBUILDMD ---&gt; BUILDMD\n    CIBUILDSITE ---&gt; PAGES\n    PAGES &lt;-.-&gt; SITE\n    CIBUILDSITE ---&gt; BUILDSITE\n    BUILT -.- BUILDSITE\n    VLESS -.- BUILDSITE\n    BUILDMD --&gt; BUILT\n    BUILDSITE --&gt; SITE"
  },
  {
    "objectID": "intro.html#development",
    "href": "intro.html#development",
    "title": "1  Introduction",
    "section": "1.3 Development",
    "text": "1.3 Development\nDevelopment of The Workbench is overseen by Zhian N. Kamvar. New features are added incrementally as pull requests. Pushes to the main branch are rare and discouraged. New features must have tests associated (with the exception of {varnish}).\nIf you are interested, we have documentation for the release process available."
  },
  {
    "objectID": "intro.html#documentation",
    "href": "intro.html#documentation",
    "title": "1  Introduction",
    "section": "1.4 Documentation",
    "text": "1.4 Documentation\nReference documentation for individual functions for each package is written alongside the function using {roxygen2}.\nThis documentation is generated by devtools::document()"
  },
  {
    "objectID": "intro.html#testing",
    "href": "intro.html#testing",
    "title": "1  Introduction",
    "section": "1.5 Testing",
    "text": "1.5 Testing\nTests for each package live in tests/testthat/ and follow a test-[file-name].R naming convention. These are controlled by the {testthat} package and run by devtools::test().\nYou can find more information about testing the core packages in Testing The Workbench"
  },
  {
    "objectID": "intro.html#continous-integration",
    "href": "intro.html#continous-integration",
    "title": "1  Introduction",
    "section": "1.6 Continous Integration",
    "text": "1.6 Continous Integration\nThe continous integration for each package tests on Ubuntu, MacOS, and Windows systems with the last five versions of R (same as the RStudio convention).\nMore information about the Continous Integration can be found in the Continuous Integration section of the testing section.\n\nComing up:\n\nTesting Pull Requests (Locally and on your fork)\nResources for R package development\nAdding functionality to {sandpaper}\nAdding functionality to {pegboard}\nAdding styling elements to {varnish}\nAdding functionality to carpentries/actions"
  },
  {
    "objectID": "setup.html#software-tools",
    "href": "setup.html#software-tools",
    "title": "2  System Setup",
    "section": "2.1 Software Tools",
    "text": "2.1 Software Tools\nDevelopment of Workbench components requires the same toolchain for working on lessons:\n\nR\npandoc\nGit\n\nIt is recommended to have the latest versions of R and pandoc available. You need at least git 2.28 for security purposes.\n\n\nR version\n---\n\n\nR version 4.3.0 (2023-04-21) -- \"Already Tomorrow\"\nCopyright (C) 2023 The R Foundation for Statistical Computing\nPlatform: x86_64-pc-linux-gnu (64-bit)\n\nR is free software and comes with ABSOLUTELY NO WARRANTY.\nYou are welcome to redistribute it under the terms of the\nGNU General Public License versions 2 or 3.\nFor more information about these matters see\nhttps://www.gnu.org/licenses/.\n\n\n\npandoc version\n---\n\n\npandoc 2.19.2\nCompiled with pandoc-types 1.22.2.1, texmath 0.12.5.2, skylighting 0.13,\nciteproc 0.8.0.1, ipynb 0.2, hslua 2.2.1\nScripting engine: Lua 5.4\nUser data directory: /home/runner/.local/share/pandoc\nCopyright (C) 2006-2022 John MacFarlane. Web:  https://pandoc.org\nThis is free software; see the source for copying conditions. There is no\nwarranty, not even for merchantability or fitness for a particular purpose.\n\n\n\ngit version\n---\n\n\ngit version 2.40.1"
  },
  {
    "objectID": "setup.html#r-packages",
    "href": "setup.html#r-packages",
    "title": "2  System Setup",
    "section": "2.2 R Packages",
    "text": "2.2 R Packages\nOnce you have these installed, make sure to install ALL of the dependencies for the workbench:\ninstall.packages(c(\"sandpaper\", \"pegboard\", \"varnish\", \"tinkr\"),\n  dependencies = TRUE,\n  repos = c(getOption(\"repos\"), \"https://carpentries.r-universe.dev\"))\n\n\n\n\n\n\nWorking on Linux?\n\n\n\nIf you are on Linux, you will run into a couple of fun aspects that you may already be familiar with, especially if you have ever tried to install bioinformatic software:\n\nhaving to also install some extra C libraries (which are akin to R packages, but for C), such as the xslt library.\nhaving to build all packages from source\n\nYou can find detailed instructions in The Sandpaper Setup Guide, but the relevant commands are below.\n\nSystem Dependencies\nHere is the gist for Ubuntu Users to get system dependencies set up. Use The Carpentries R-Universe API to get all of the system dependencies. Here’s how to do that via CURL:\ncurl https://carpentries.r-universe.dev/stats/sysdeps 2&gt; /dev/null | jq -r '.headers[0] | select(. != null)'\nThis list can be sent to apt-get install to install everything:\nsudo apt-get install -y \\\n  $(curl https://carpentries.r-universe.dev/stats/sysdeps 2&gt; /dev/null | jq -r '.headers[0] | select(. != null)') 2&gt; /dev/null \\\n  || echo \"Not on Ubuntu\"\n\n\nBinary Packages\nTo get binary packages for your system, I will admit that it’s slightly confusing because they bury the instructions for registering your system to use binaries in the admin pages and even then, it’s kinda long. The gist is that you need to do two things:\n\nset your HTTPUserAgent header to state your R version and platform\nadd the packagemanager CRAN-like repository to R’s options:\n\nHere’s a script that you can copy and paste into ~/.Rprofile which will be run every time you start R\nlocal({\n  # Set the default HTTP user agent to get pre-built binary packages\n  RV &lt;- getRversion()\n  OS &lt;- paste(RV, R.version[\"platform\"], R.version[\"arch\"], R.version[\"os\"])\n  codename &lt;- sub(\"Codename.\\t\", \"\", system2(\"lsb_release\", \"-c\", stdout = TRUE))\n  options(HTTPUserAgent = sprintf(\"R/%s R (%s)\", RV, OS))\n\n  # register the repositories for The Carpentries and CRAN\n  options(repos = c(\n    carpentries = \"https://carpentries.r-universe.dev/\",\n    CRAN = paste0(\"https://packagemanager.posit.co/all/__linux__/\", codename, \"/latest\")\n  ))\n})\nWhen you have this set up, you can then install the workbench packages:\n# Install The Workbench and dependencies\ninstall.packages(c(\"sandpaper\", \"varnish\", \"pegboard\", \"tinkr\"), dep = TRUE)\n\n\n\nThe {sandpaper} package comes with the {usethis} package embedded (though this may change in the future). In addition, you will need the {devtools} for development.\nI would also highly recommend the {pandoc} package for managing pandoc versions (NOTE: this requires you to have a personal access token set up).\ninstall.packages(\"devtools\")\ninstall.packages(\"pandoc\")\nOnce you have devtools, be sure to run devtools::dev_sitrep() and usethis::git_sitrep() to make sure you have the tools to build The Workbench:\ndevtools::dev_sitrep()\n#&gt; ── R ───────────────────────────────────────────────────────────────────────────\n#&gt; • version: 4.3.0\n#&gt; • path: '/usr/lib/R/'\n#&gt; ── devtools ────────────────────────────────────────────────────────────────────\n#&gt; • version: 2.4.5\n#&gt; ── dev package ─────────────────────────────────────────────────────────────────\n#&gt; • package: &lt;unset&gt;\n#&gt; • path: &lt;unset&gt;\n#&gt; ✔ All checks passed\n\nusethis::git_sitrep()\n#&gt; Git config (global)\n#&gt; • Name: 'Zhian N. Kamvar'\n#&gt; • Email: 'zkamvar@gmail.com'\n#&gt; • Global (user-level) gitignore file: &lt;unset&gt;\n#&gt; • Vaccinated: FALSE\n#&gt; ℹ See `?git_vaccinate` to learn more\n#&gt; ℹ Defaulting to 'https' Git protocol\n#&gt; • Default Git protocol: 'https'\n#&gt; • Default initial branch name: 'main'\n#&gt; GitHub\n#&gt; • Default GitHub host: 'https://github.com'\n#&gt; • Personal access token for 'https://github.com': '&lt;discovered&gt;'\n#&gt; • GitHub user: 'zkamvar'\n#&gt; • Token scopes: 'gist, repo, user, workflow'\n#&gt; • Email(s): 'zkamvar@gmail.com (primary)', ...\n#&gt; Git repo for current project\n#&gt; ℹ No active usethis project\nCreated on 2023-05-30 with reprex v2.0.2"
  },
  {
    "objectID": "setup.html#development-workflow",
    "href": "setup.html#development-workflow",
    "title": "2  System Setup",
    "section": "2.3 Development Workflow",
    "text": "2.3 Development Workflow\nThis development workflow is known as Test Driven Development in which a test is written before things work. This way, we can confirm that a bug is fixed once it passes the tests and we have confidence that it will not fail again.\n\nopen RStudio and switch to the project for the package you are working on\ncheckout a new branch for your feature/bug\nload package via devtools::load_all() or ctrl+shift+L ( use cmd on macOS) to load the package NAMESPACE\nrun tests (either via devtools::test() or ctrl+shift+T to run the entire test suite OR to test a single file, use the “run tests” button in a test file or run testthat::test_local(filter = '[FILE SLUG]')\nmodify tests for new functionality/bug fix\nadd functionality/bug fix and move to 3 unless you are ready to push\nrun check with devtools::check() or ctrl+shift+E"
  },
  {
    "objectID": "testing.html#introduction",
    "href": "testing.html#introduction",
    "title": "3  Testing The Workbench",
    "section": "3.1 Introduction",
    "text": "3.1 Introduction\n\nThe first stage of your testing journey is to become convinced that testing has enough benefits to justify the work. For some of us, this is easy to accept. Others must learn the hard way.\n— Wickham and Bryan, Testing Basics, R Packages second edition\n\n\nIf you use software that lacks automated tests, you are the tests.\n— Jenny Bryan source tweet (2018-09-22 01:13 UTC)\n\nEvery single package that runs code in the lesson infrastructure is tested before it ever reaches any lesson. This is important because we want to give the lesson authors and maintainers as much freedom as they need to write a lesson while maintaining predictability and integrity. We also want to give our community confidence that this system works.\nWhenever a new feature or bug fix is added to The Workbench, it is imperative that a test is associated and verified before it gets sent into production.\nTests can be run locally and via continuous integration. This page introduces some of the testing strategies used in The Workbench and the caveats that come with these strategies."
  },
  {
    "objectID": "testing.html#unit-testing",
    "href": "testing.html#unit-testing",
    "title": "3  Testing The Workbench",
    "section": "3.2 Unit Testing",
    "text": "3.2 Unit Testing\nThe tests under test/testthat/ are run in alphabetical order using the {testthat} package (see https://r-pkgs.org/testing-basics.html) via devtools::test() or devtools::check().\n\n3.2.1 sandpaper\n\n\n3.2.2 pegboard\n\n\n3.2.3 varnish\n\n\n3.2.4 vise"
  },
  {
    "objectID": "testing.html#ci",
    "href": "testing.html#ci",
    "title": "3  Testing The Workbench",
    "section": "3.3 Continous Integration",
    "text": "3.3 Continous Integration\nAll the unit tests are run in continuous integration for every push and pull request that occurs. They also run every week. This provisions the current releases of the R package dependencies along with development versions of critical dependencies such as {renv}.\nIn continous integration, we run on with the following conditions to make sure it works not only on GitHub, but also on local user machines:\n\ntest coverage (no package structure) with released versions on Ubuntu Linux (though reporting is stalled)\nFor each platform (Ubuntu Linux, macOS, and Windows)\n\nR CMD check, which checks the structure of the package and documentation\nall run on these versions of R: current, devel, and two previous R versions\n\n\nBecause of occasional provisioning failures on macOS and Windows, we require only that Ubuntu Linux latest version passes check for merging pull requests."
  },
  {
    "objectID": "testing.html#lesson-integration-testing",
    "href": "testing.html#lesson-integration-testing",
    "title": "3  Testing The Workbench",
    "section": "3.4 Lesson Integration Testing",
    "text": "3.4 Lesson Integration Testing"
  },
  {
    "objectID": "flow.html#introduction",
    "href": "flow.html#introduction",
    "title": "4  Flow Diagrams",
    "section": "4.1 Introduction",
    "text": "4.1 Introduction\nThis section builds on The broad workflow and details the internal process that are invoked with the sandpaper::build_lesson() function. If you look at the source for this function, it contains a total of sevens significant lines of code (many more due to documentation and comments).\nThe pre-flight steps all happen before a single source file is built. These check for pandoc, validate the lesson, and configure global elements. The last two lines are responsible for building the site and combining them with the global variables and templates.\nUsers will invoke this function in the following ways:\n\n\n\n\n\n\n\n\nvenue\nfunction\npurpose\n\n\n\n\nlocal\nsandpaper::build_lesson()\nrender content for offline use\n\n\nlocal\nsandpaper::serve()\ndynamically render and preview content\n\n\nremote\nsandpaper:::ci_deploy()\nrender content and deploy to branches\n\n\n\nAll of these methods will call sandpaper::validate_lesson() (which also sets up global metadata and menu variables) and the two-step internal functions sandpaper:::build_markdown() and sandpaper:::build_site(). Below, I break down and detail the process for each."
  },
  {
    "objectID": "flow.html#preflight-checks",
    "href": "flow.html#preflight-checks",
    "title": "4  Flow Diagrams",
    "section": "4.2 Preflight Checks",
    "text": "4.2 Preflight Checks\nBefore a lesson can be built, we need to confirm the following:\n\nWe have access to the tools needed to build a lesson (e.g. pandoc). This is achieved via the sandpaper::check_pandoc()\nWe are inside a lesson that can be built with The Carpentries Workbench"
  },
  {
    "objectID": "flow.html#validate-lesson",
    "href": "flow.html#validate-lesson",
    "title": "4  Flow Diagrams",
    "section": "4.3 validate_lesson()",
    "text": "4.3 validate_lesson()\nThe lesson validator is a bit of a misnomer. Yes, it does peform lesson validation, which it does so through the methods in the pegboard::Lesson R6 class.\nIn order to use thse methods, it first loads the lesson, via the sandpaper::this_lesson() function, which loads and caches the pegboard::Lesson object. It also caches elements that are mostly duplicated across episodes with small tweaks for each episode:\n\nmetadata in JSON-LD format\nsidebar\nextras menu for learner and instructor views"
  },
  {
    "objectID": "flow.html#build-markdown",
    "href": "flow.html#build-markdown",
    "title": "4  Flow Diagrams",
    "section": "4.4 build_markdown()",
    "text": "4.4 build_markdown()\n\n4.4.1 Generating Markdown\nMarkdown generation for the lesson is controlled by the internal function sandpaper:::build_markdown().\nWhen a lesson contains R Markdown files, these need to have content rendered to markdownsot hat we can further process them. This content is processed with the {knitr} R package in a separate R process. Markdown source content on the other hand is copied to the site/built folder.\nBecause R Markdown files can take some time to render, we use MD5 sums of the episode contents (stored in the site/built/md5sum.txt file) to skip any files that have not changed.\n\n\n\n\nsequenceDiagram\n    autonumber\n    participant episodes/episode.Rmd\n    box rgb(255, 214, 216) The Workbench\n    participant {sandpaper}\n    end\n    box rgb(230, 234, 240) Document Engine\n    participant {renv}\n    participant {knitr}\n    end\n    box rgb(255, 231, 168) Generated Files\n    participant site/built/md5sum.txt\n    participant site/built/episode.md\n    end\n\n    site/built/md5sum.txt --&gt;&gt; {sandpaper}: READ file cache\n    {sandpaper} --&gt;&gt; {knitr}: RUN conversion\n    episodes/episode.Rmd --&gt;&gt; {knitr}: PROCESS changed file(s)\n    {knitr} --&gt;&gt; site/built/episode.md: WRITE Markdown\n    {sandpaper} --&gt;&gt; site/built/md5sum.txt: WRITE file cache\n\n\n\n\n\n\n\n\n\n\n\nPackage Cache and Reproducibility\n\n\n\nOne package that is missing from the above diagram is {renv} and that’s partially because it has an indirect effect on the lesson: it provisions the packages needed to build the lesson.\nWhen episodes are rendered from R Markdown to Markdown, we attempt to reproduce the build environment as closely as possible by using the {renv} package. If the global package cache from {renv} is available, then the lesson profile is activated before the episode is sent to {knitr} and R will use the packages provided in that profile. This has two distinct advantages:\n\nThe user does not have to worry about overwriting packages in their own library (i.e. a graduate researcher working on their dissertation does not want to have to rewrite their analyses because of a new version of {sf})\nThe package versions will be the same as the versions on the GitHub version of the site, which means that there will be no false positives of new errors popping up\n\nFor details on the package cache, see the Building Lessons With A Package Cache article.\n\n\nAt this step, the markdown has been written and the state of the cache is updated so if we re-run this function, then it will show that no changes have occured. After this step, the internal function sandpaper:::build_site() is run where the markdown file that we just created is converted to HTML with pandoc and stored in an R object. This R object is then manipulated and then written to an HTML file with the {varnish} website templates applied.\nWe use this function in the pull request workflows to demonstrate the changes in markdown source files, which is useful when package versions change, causing the output to potentially change."
  },
  {
    "objectID": "flow.html#build-site",
    "href": "flow.html#build-site",
    "title": "4  Flow Diagrams",
    "section": "4.5 build_site()",
    "text": "4.5 build_site()\nThe following sections will discuss the HTML generation (the following section), manipulation (the section after that), and applying the template (the final section) separately because, while these processes are each run via the internal sandpaper:::build_site() function, they are functionally separate.\n\n4.5.1 Generating HTML\nEach markdown file is processed into HTML via pandoc and returned to R as text. This is done via the internal function sandpaper:::render_html().\n\n\n\n\nsequenceDiagram\n    autonumber\n    box rgb(255, 214, 216) The Workbench\n    participant {sandpaper}\n    end\n    box rgb(230, 234, 240) Document Engine\n    participant pandoc\n    end\n    box rgb(255, 231, 168) Generated Files\n    participant site/built/episode.md\n    end\n\n    {sandpaper} --&gt;&gt; pandoc: LOAD pandoc with lua filters\n    site/built/episode.md --&gt;&gt; pandoc: READ markdown\n    pandoc --&gt;&gt; {sandpaper}: RENDER HTML as text\n\n\n\n\n\nFrom here, the HTML exists as the internal body content of a website without a header, footer, or any styling. It is nearly ready for insertion into a website template. The next section details the flow we use to tweak the HTML content.\n\n\n4.5.2 Processing HTML\nThe HTML needs to be tweaked because the output from pandoc, even with our lua filters, still needs some modification. We tweak the content by first converting the HTML into an Abstract Syntax Tree (AST). This allows us to programmatically manipulate tags in the HTML without resorting to using regular expressions.\nIn this part, we update links, images, headings, structure that we could not fix using lua filters. We then use the information from the episode to complete the global menu variable with links to the second level headings in the episode.\n\n\n\n\nsequenceDiagram\n    autonumber\n    box rgb(255, 214, 216) The Workbench\n    participant {sandpaper}\n    end\n    box rgb(230, 241, 255) R Object\n    participant HTML(AST)\n    end\n    box rgb(230, 234, 240) Helper Package\n    participant {xml2}\n    end\n\n    {sandpaper} --&gt;&gt; {xml2}: READ HTML\n    {xml2} --&gt;&gt; HTML(AST): PARSE HTML\n    activate {sandpaper}\n    note right of HTML(AST): sandpaper:::fix_nodes()\n    {xml2} --&gt;&gt; HTML(AST): update structure\n    HTML(AST) --&gt;&gt; {sandpaper}: extract menu items\n    note right of {sandpaper}: generate learner and instructor versions\n    deactivate {sandpaper}\n\n\n\n\n\n\n\n\n\n\n\nWorking With XML\n\n\n\nWorking with XML data is perhaps one of the strangest experiences for an R user because in R, functions will normally return a copy of the data, but when working with an XML document parsed by {xml2}, the data is modified in place.\nIt allows us to do neat things, but there is a learning curve associated.\n\n\n\n\n4.5.3 Applying Website Template\nNow that we have an HTML AST that has been corrected and associated metadata, we are ready to write this to HTML. This process is achieved by passing the AST and metadata to {pkgdown} where it performs a little more manipulation, applies the {varnish} template, and writes it to disk.\n\n\n\n\nsequenceDiagram\n    autonumber\n    box rgb(255, 214, 216) The Workbench\n    participant {sandpaper}\n    participant {varnish}\n    end\n    box rgb(230, 241, 255) R Object\n    participant HTML(AST)\n    end\n    box rgb(230, 234, 240) Helper Package\n    participant {pkgdown}\n    end\n    box rgb(255, 231, 168) Generated Files\n    participant site/docs/episode.html\n    end\n\n    activate {sandpaper}\n    {sandpaper} --&gt;&gt; {pkgdown}: Set global menu variables\n    HTML(AST) --&gt;&gt; {pkgdown}: Hand off HTML to pkgdown\n    deactivate {sandpaper}\n    activate {pkgdown}\n    {varnish} --&gt;&gt; {pkgdown}: Load template\n    {pkgdown} --&gt;&gt; site/docs/episode.html: WRITE website\n    deactivate {pkgdown}"
  },
  {
    "objectID": "sandpaper/intro.html",
    "href": "sandpaper/intro.html",
    "title": "5  The {sandpaper} package",
    "section": "",
    "text": "nothing to see here yet"
  },
  {
    "objectID": "sandpaper/testing.html#introduction",
    "href": "sandpaper/testing.html#introduction",
    "title": "6  Testing {sandpaper}",
    "section": "6.1 Introduction",
    "text": "6.1 Introduction\n{sandpaper} is the largest package and the main user and deployment interface for The Workbench. The tests are all designed to work within a lesson context, which means a couple of things to be aware of.\n\nSome tests will take a long time to run. IO procedures are often one of the most time-consuming steps in computing and {sandpaper} does a lot of it.\nMost tests will be dependent on the previous tests in a file. Because the tests work on a folder on disk, we need to provision different scenarios of lesson state. It is far simpler to do this by side-effect rather than copying, setting up, and tearing down the state of the lesson for each and every test."
  },
  {
    "objectID": "sandpaper/testing.html#test-setup",
    "href": "sandpaper/testing.html#test-setup",
    "title": "6  Testing {sandpaper}",
    "section": "6.2 Test Setup",
    "text": "6.2 Test Setup\nThere is nothing that you as the contributor/developer need to do to set up for running these tests beyond what you have already done in your development setup. This section describes conceptually how {testthat} and {sandpaper} setup the testing environment after you run devtools::test().\nIn short, this is the process:\n\n{sandpaper} is loaded\nHelper test files are loaded\nThe setup script is loaded, which provisions the test lesson\nEach test file matchingtests/testthat/test-*.R is run, resetting the test lesson at the top of each file.\n\n\n6.2.1 Test Helpers\nSandpaper has three test helpers that handle some of the more tedious side-effects of testing.\n\nhelper-hash.R\n\nExpectation expect_hashed() that an episode file MD5 sum (expected) matches the MD5 sum (actual) we recorded in the site/built/md5sum.txt database.\n\nhelper-processing.R\n\nProvides an output string that demonstrates a screen output of a file being processed by {knitr}. This is used with expect_output().\n\nhelper-snap-transform.R\n\nA function that is passed to the transform parameter of expect_snapshot() and will mask the temporary directory path so that the snapshot does not continuously invalidate on every run.\n\n\n\n\n6.2.2 Setup Script\nThe first script to run is tests/testthat/setup.R, where a test lesson and a local git remote is created and stored in a temporary location for the duration of the test suite and a reset function is exposed for the tests."
  },
  {
    "objectID": "sandpaper/testing.html#conditionally-skipped-tests",
    "href": "sandpaper/testing.html#conditionally-skipped-tests",
    "title": "6  Testing {sandpaper}",
    "section": "6.3 Conditionally Skipped Tests",
    "text": "6.3 Conditionally Skipped Tests\nEach link below will open a code search for the different types of skipped tests in {sandpaper}\n\nskip_on_os\n\nThese are often tests that are skipped on Windows, usually for the reason that {renv} and filepaths behave slightly differently on Windows in a continuous integration setting.\n\nskip_if\n\nTests that are skipped under various conditions. For example, if Git is not installed on a system, we should not test any of the CI functions because they rely on Git.\n\nskip(\"&lt;for reasons&gt;\")\n\nThis pattern is more rare. It’s really useful in a situation where you are refactoring and know that a lot of tests will fail. If you sprinkle in these skips, you can focus on testing the core functionality of the refactor and then address the side-effects. Regarding the skips that remain: during testing, sometimes we encounter a ghost in the machine and we cannot set up the right conditions to run the test properly or the test was created with an earlier model of the package that we haven’t been able to shake. In these cases, instead of deleting the test or commenting out code, we add the skip() function and write a message of why we skipped it so if we need to come back to it later, we can."
  },
  {
    "objectID": "sandpaper/testing.html#continuous-integration",
    "href": "sandpaper/testing.html#continuous-integration",
    "title": "6  Testing {sandpaper}",
    "section": "6.4 Continuous Integration",
    "text": "6.4 Continuous Integration"
  },
  {
    "objectID": "pegboard/intro.html",
    "href": "pegboard/intro.html",
    "title": "7  The {pegboard} package",
    "section": "",
    "text": "nothing to see here yet"
  },
  {
    "objectID": "varnish/intro.html#introduction",
    "href": "varnish/intro.html#introduction",
    "title": "8  The {varnish} package",
    "section": "8.1 Introduction",
    "text": "8.1 Introduction\nThe {varnish} package is a weird little package in that it does not contain any actual R code. It’s purpose is to host HTML templates along with the CSS and JavaScript needed to display the lesson.\nWe take advantage of the fact that the only thing actually required to install an R package is the presence of a DESCRIPTION file1. These all live inside the inst/ folder, which is a place that allows files to be installed along with the package.\nThe {pkgdown} package uses this as a mechanism for package developers to override the default styling, creating customized documentation websites such as the rOpenSci documentation sites: https://docs.ropensci.org/rotemplate/.\nThis allows people to update the lesson styling however they wish2 and while we could include it in {sandpaper}, it’s best kept separate so that people can update {varnish} without needing to update the entire tool suite."
  },
  {
    "objectID": "varnish/intro.html#design-and-implementation-background",
    "href": "varnish/intro.html#design-and-implementation-background",
    "title": "8  The {varnish} package",
    "section": "8.2 Design and Implementation Background",
    "text": "8.2 Design and Implementation Background\nThe design for the frontend was created by Emily de la Mettrie in 2021 after consultation with Zhian N. Kamvar and François Michonneau using examples from The Unix Shell and parts of Exploring Data Frames for content cues.\nThe final figma design project3 was then handed off to a team at Bytes.co, who translated the designs to CSS and JavaScript, subcontracted an a11y testing company to interactively test the prototype for a11y issues.\nThe prototype we recieved from Bytes.co was a Jekyll template serving HTML files. Zhian created a staging repository called shellac to transform the site from one that was served via static site generator to one that was standalone. The preview is preserved at https://zkamvar.github.io/shellac/student_carpentries.html.\nThis site was then stripped of the added into {varnish} in carpentries/varnish#14 between 2022-01-10 and 2022-01-24, when the 1.0.0 release of {varnish} was created and the sandpaper docs website was updated to use the new version of the HTML, CSS, and JavaScript."
  },
  {
    "objectID": "releases.html#background",
    "href": "releases.html#background",
    "title": "9  Release Process for Workbench Packages",
    "section": "9.1 Background",
    "text": "9.1 Background\nThe workbench contains three main packages:\n\n{sandpaper}: user interface and workflow engine\n{pegboard}: parsing and validation engine\n{varnish}: HTML templates, CSS, and JS elements\n\nEach of these packages are available on the Carpentries R-Universe and new versions are checked for hourly. This allows folks to get up-to-date versions of The Workbench packages built for their system without running out of GitHub API query attempts.\nIn order to maintain quality, packages are only sent to the R-Universe if they have been formally released on GitHub (as specified in the packages.json configuration file). This allows us to incrementally add new experimental features without changing the stable deployments."
  },
  {
    "objectID": "releases.html#release-process",
    "href": "releases.html#release-process",
    "title": "9  Release Process for Workbench Packages",
    "section": "9.2 Release Process",
    "text": "9.2 Release Process\nWhen a package is ready for release we use the following checklist:\n\nUpdate version number in DESCRIPTION\nAdd NEWS for the changes in this version\nEnsure all changes are committed and pushed\nadd new signed tag with the name “ X.Y.Z”\n# example: create a signed (-s) tag for sandpaper 3.3.3\ngit tag -s 3.3.3 -m 'sandpaper 3.3.3'\ncreate a release on github from the new tag\n\n\n\n\n\n\n\nNote\n\n\n\nZhian likes to create tags via the command line because he has set up his git configuration to use a gpg signature so the tags and the releases are both verified.\n\n\nThe last two items can be achieved in a single step with the github cli with the command gh release create X.Y.Z for the version number\ngh release create 3.3.3\n# ? Title (optional) sandpaper 3.3.3\n# ? Release notes  [Use arrows to move, type to filter]\n#   Write my own\n# &gt; Write using generated notes as template\n#   Leave blank\nSelecting “Write using generated notes as a template” opens an editor and populates it with the pull requests that have been accepted since the last release.\nOnce the relase is created on GitHub, then the package will be available on the R-Universe in about an hour or less."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "10  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Wickham, Hadley, and Jennifer Bryan. 2023. “R\nPackages (2e).” https://r-pkgs.org/."
  }
]